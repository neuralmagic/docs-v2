"use strict";(self.webpackChunkdocs_neuralmagic_com=self.webpackChunkdocs_neuralmagic_com||[]).push([[3276],{2176:(e,i,s)=>{s.r(i),s.d(i,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>t,metadata:()=>a,toc:()=>c});var n=s(5893),o=s(1151);const t={slug:"/",title:"Home",sidebar_position:0},r="Neural Magic Docs",a={id:"home",title:"Home",description:"Welcome to software-delivered AI... Welcome to Neural Magic!",source:"@site/docs/home.mdx",sourceDirName:".",slug:"/",permalink:"/next/",draft:!1,unlisted:!1,editUrl:"https://github.com/neuralmagic/docs/docs/home.mdx",tags:[],version:"current",sidebarPosition:0,frontMatter:{slug:"/",title:"Home",sidebar_position:0},sidebar:"tutorialSidebar",next:{title:"Getting Started",permalink:"/next/get-started/"}},l={},c=[{value:"Selecting a Model",id:"selecting-a-model",level:2},{value:"Optimizing a Model",id:"optimizing-a-model",level:2},{value:"Deploying a Model",id:"deploying-a-model",level:2},{value:"Next Steps",id:"next-steps",level:2},{value:"Sections",id:"sections",level:3},{value:"Tasks",id:"tasks",level:3}];function d(e){const i={a:"a",h1:"h1",h2:"h2",h3:"h3",hr:"hr",img:"img",li:"li",ol:"ol",p:"p",ul:"ul",...(0,o.a)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(i.h1,{id:"neural-magic-docs",children:"Neural Magic Docs"}),"\n",(0,n.jsx)(i.p,{children:"Welcome to software-delivered AI... Welcome to Neural Magic!\nWe enable you to deploy deep learning models on commodity CPUs with GPU-class performance."}),"\n",(0,n.jsx)(i.p,{children:"Neural Magic's guided experiences and documentation will show you how to integrate performant and optimized deep learning into your application.\nOur guided experiences and documentation enable you to discover how to unlock the full potential of your ML environments through increased performance, decreased costs, and decreased energy usage."}),"\n",(0,n.jsx)(i.p,{children:(0,n.jsx)(i.img,{alt:"Neural Magic Flows",src:s(3454).Z+"",width:"7696",height:"5196"})}),"\n",(0,n.jsx)(i.h2,{id:"selecting-a-model",children:"Selecting a Model"}),"\n",(0,n.jsx)(i.p,{children:"Begin your journey with Neural Magic by selecting the right model for your application. You have two primary options:"}),"\n",(0,n.jsxs)(i.ol,{children:["\n",(0,n.jsx)(i.li,{children:"SparseZoo: An open-source repository filled with a variety of sparsified models. SparseZoo provides you with readily available models that are optimized for efficient deployment. Choose from a wide range of models that are pre-sparsified and ready to be deployed in your applications."}),"\n",(0,n.jsx)(i.li,{children:"Your Own Models: If you have a custom model developed in PyTorch or ONNX format, you can directly integrate it with Neural Magic\u2019s tools. This flexibility allows you to apply Neural Magic\u2019s optimization and deployment technologies to models specifically tailored to your unique use cases."}),"\n"]}),"\n",(0,n.jsx)(i.h2,{id:"optimizing-a-model",children:"Optimizing a Model"}),"\n",(0,n.jsx)(i.p,{children:"Optimizing your models for better performance and efficiency is crucial. With Neural Magic\u2019s SparseML, this process is streamlined using state-of-the-art (SOTA) research techniques. SparseML provides:"}),"\n",(0,n.jsxs)(i.ul,{children:["\n",(0,n.jsx)(i.li,{children:"Advanced Sparsification Techniques: Utilize cutting-edge research in sparsity to optimize your models. This includes techniques like pruning and quantization, which help in reducing model size and improving inference speed."}),"\n",(0,n.jsx)(i.li,{children:"Accessible Optimization: SparseML is designed to be user-friendly, enabling anyone to apply these optimization techniques to their models. Whether you are a seasoned ML practitioner or new to the field, SparseML guides you through the process of optimizing your models for better performance."}),"\n"]}),"\n",(0,n.jsx)(i.h2,{id:"deploying-a-model",children:"Deploying a Model"}),"\n",(0,n.jsx)(i.p,{children:"With Neural Magic\u2019s DeepSparse, you can deploy your selected model with exceptional performance on CPUs. DeepSparse is designed to provide GPU-class performance, solely utilizing CPU resources. This approach brings a significant advantage in terms of accessibility and cost-effectiveness for deploying deep learning models. Here\u2019s what DeepSparse offers:"}),"\n",(0,n.jsxs)(i.ul,{children:["\n",(0,n.jsx)(i.li,{children:"Efficient CPU Deployments: Leveraging the power of sparsity, DeepSparse allows you to deploy models on CPUs without compromising on performance, making the most of the available hardware."}),"\n",(0,n.jsx)(i.li,{children:"Seamless Integration: DeepSparse is built to be easily integrated into your existing applications, reducing the need for extensive code rewriting and accelerating the deployment process."}),"\n"]}),"\n",(0,n.jsx)(i.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,n.jsx)(i.p,{children:"This was a quick look at Neural Magic\u2019s suite of products.\nNow, we invite you to explore our products through guided experiences and documentation."}),"\n",(0,n.jsx)(i.h3,{id:"sections",children:"Sections"}),"\n",(0,n.jsx)(i.p,{children:"The following sections will help you get started with Neural Magic's products:"}),"\n",(0,n.jsxs)("div",{className:"cards-container",children:[(0,n.jsxs)("a",{href:"/get-started",children:[(0,n.jsx)("h6",{children:"Getting Started"}),(0,n.jsx)("p",{children:"A step-by-step introduction to Neural Magic's platform."})]}),(0,n.jsxs)("a",{href:"/guides",children:[(0,n.jsx)("h6",{children:"Guides"}),(0,n.jsx)("p",{children:"Concepts, how-to, product, and API-level documents for Neural Magic's software."})]}),(0,n.jsxs)("a",{href:"/products",children:[(0,n.jsx)("h6",{children:"Products"}),(0,n.jsx)("p",{children:"Overview of Neural Magic's products with API docs, CLI docs, release notes, and more."})]}),(0,n.jsxs)("a",{href:"/details",children:[(0,n.jsx)("h6",{children:"Details"}),(0,n.jsx)("p",{children:"Technical details about Neural Magic's software."})]})]}),"\n",(0,n.jsx)(i.h3,{id:"tasks",children:"Tasks"}),"\n",(0,n.jsx)(i.p,{children:"If you have a specific domain or task in mind, dive into the following sections:"}),"\n",(0,n.jsxs)("div",{className:"cards-container",children:[(0,n.jsxs)("a",{href:"/generative-ai",children:[(0,n.jsx)("h6",{children:"Generative AI"}),(0,n.jsx)("p",{children:"Explore improved performance and efficiency for generative AI tasks such as causal language modeling."})]}),(0,n.jsxs)("a",{href:"/computer-vision",children:[(0,n.jsx)("h6",{children:"Computer Vision"}),(0,n.jsx)("p",{children:"Explore improved performance and efficiency for computer vision tasks such as object detection and image classification."})]}),(0,n.jsxs)("a",{href:"/nlp",children:[(0,n.jsx)("h6",{children:"Natural Language Processing"}),(0,n.jsx)("p",{children:"Explore improved performance and efficiency for NLP tasks such as question answering and text classification."})]})]}),"\n",(0,n.jsx)("br",{}),"\n",(0,n.jsx)(i.hr,{}),"\n",(0,n.jsxs)(i.p,{children:["\u2705 Join our ",(0,n.jsx)(i.a,{href:"https://join.slack.com/t/discuss-neuralmagic/shared_invite/zt-q1a1cnvo-YBoICSIw3L1dmQpjBeDurQ",children:"community"})," if you need any help or ",(0,n.jsx)(i.a,{href:"https://neuralmagic.com/deep-sparse-community/#subscribe",children:"subscribe"})," for regular email updates."]}),"\n",(0,n.jsxs)(i.p,{children:["\u2705 Check out our ",(0,n.jsx)(i.a,{href:"https://github.com/neuralmagic",children:"GitHub repositories"})," and give us a \u2b50."]}),"\n",(0,n.jsxs)(i.p,{children:["\u2705 Help us improve this ",(0,n.jsx)(i.a,{href:"https://github.com/neuralmagic/docs",children:"documentation"}),"."]})]})}function h(e={}){const{wrapper:i}={...(0,o.a)(),...e.components};return i?(0,n.jsx)(i,{...e,children:(0,n.jsx)(d,{...e})}):d(e)}},3454:(e,i,s)=>{s.d(i,{Z:()=>n});const n=s.p+"assets/images/nm-flows-cf2460a2fafdda658009c67c102ece80.png"},1151:(e,i,s)=>{s.d(i,{Z:()=>a,a:()=>r});var n=s(7294);const o={},t=n.createContext(o);function r(e){const i=n.useContext(t);return n.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function a(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),n.createElement(t.Provider,{value:i},e.children)}}}]);