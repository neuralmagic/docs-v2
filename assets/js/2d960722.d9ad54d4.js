"use strict";(self.webpackChunkdocs_neuralmagic_com=self.webpackChunkdocs_neuralmagic_com||[]).push([[935],{1024:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>l,contentTitle:()=>t,default:()=>p,frontMatter:()=>a,metadata:()=>r,toc:()=>c});var s=n(5893),o=n(1151);const a={slug:"/",tags:["neural-magic","deep-learning","model-optimization","sparsification","cpu-deployment"],keywords:["Neural Magic","deep learning optimization","CPU inference","sparse models","SparseML","DeepSparse"],sidebar_label:"Home",description:"Neural Magic empowers you to optimize and deploy deep learning models on CPUs with GPU-class performance. Unlock efficiency, accessibility, and cost-savings with our software solutions.",sidebar_position:0},t="Neural Magic Documentation",r={id:"home",title:"Neural Magic Documentation",description:"Neural Magic empowers you to optimize and deploy deep learning models on CPUs with GPU-class performance. Unlock efficiency, accessibility, and cost-savings with our software solutions.",source:"@site/versioned_docs/version-1.7.0/home.mdx",sourceDirName:".",slug:"/",permalink:"/docs-v2/",draft:!1,unlisted:!1,editUrl:"https://github.com/neuralmagic/docs-v2/tree/main/docs/home.mdx",tags:[{label:"neural-magic",permalink:"/docs-v2/tags/neural-magic"},{label:"deep-learning",permalink:"/docs-v2/tags/deep-learning"},{label:"model-optimization",permalink:"/docs-v2/tags/model-optimization"},{label:"sparsification",permalink:"/docs-v2/tags/sparsification"},{label:"cpu-deployment",permalink:"/docs-v2/tags/cpu-deployment"}],version:"1.7.0",sidebarPosition:0,frontMatter:{slug:"/",tags:["neural-magic","deep-learning","model-optimization","sparsification","cpu-deployment"],keywords:["Neural Magic","deep learning optimization","CPU inference","sparse models","SparseML","DeepSparse"],sidebar_label:"Home",description:"Neural Magic empowers you to optimize and deploy deep learning models on CPUs with GPU-class performance. Unlock efficiency, accessibility, and cost-savings with our software solutions.",sidebar_position:0},sidebar:"tutorialSidebar",next:{title:"Getting Started",permalink:"/docs-v2/get-started/"}},l={},c=[{value:"Selecting a Model",id:"selecting-a-model",level:2},{value:"Optimizing a Model",id:"optimizing-a-model",level:2},{value:"Deploying a Model",id:"deploying-a-model",level:2},{value:"Next Steps",id:"next-steps",level:2},{value:"Sections",id:"sections",level:3},{value:"Tasks",id:"tasks",level:3}];function d(e){const i={a:"a",h1:"h1",h2:"h2",h3:"h3",hr:"hr",img:"img",li:"li",p:"p",ul:"ul",...(0,o.a)(),...e.components},{DocCardList:a}=i;return a||function(e,i){throw new Error("Expected "+(i?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("DocCardList",!0),(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(i.h1,{id:"neural-magic-documentation",children:"Neural Magic Documentation"}),"\n",(0,s.jsx)(i.p,{children:"Welcome to software-delivered AI... Welcome to Neural Magic!\nNeural Magic empowers you to deploy deep learning models on standard CPUs, delivering GPU-class performance without the specialized hardware costs.\nOur software solutions make AI accessible, efficient, and sustainable."}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.img,{alt:"Neural Magic Flows",src:n(8825).Z+"",width:"1710",height:"1155"})}),"\n",(0,s.jsx)(i.h2,{id:"selecting-a-model",children:"Selecting a Model"}),"\n",(0,s.jsx)(i.p,{children:"Start by choosing the ideal model for your project:"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)("b",{children:"Neural Magic's Model Repositories:"})," Discover a vast selection of pre-sparsified models across popular use cases in our ",(0,s.jsx)(i.a,{href:"https://sparsezoo.neuralmagic.com/",children:"SparseZoo"})," and ",(0,s.jsx)(i.a,{href:"https://huggingface.co/neuralmagic",children:"Hugging Face"})," repositories. These models are ready for immediate, high-performance deployment."]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)("b",{children:"Custom Models:"})," Easily integrate your PyTorch or ONNX models into Neural Magic's workflow, applying cutting-edge optimization and deployment techniques tailored to your specific needs."]}),"\n"]}),"\n",(0,s.jsx)(i.h2,{id:"optimizing-a-model",children:"Optimizing a Model"}),"\n",(0,s.jsx)(i.p,{children:"Achieve unmatched model efficiency with Neural Magic's SparseML. This powerful toolkit leverages state-of-the-art research to streamline your optimization process:"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)("b",{children:"Advanced Sparsification:"})," Employ sophisticated pruning and quantization strategies to shrink model size and boost inference speed."]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)("b",{children:"User-Friendly Approach:"}),"  SparseML is intuitive and accessible, empowering users at all levels to apply advanced optimization techniques effortlessly."]}),"\n"]}),"\n",(0,s.jsx)(i.h2,{id:"deploying-a-model",children:"Deploying a Model"}),"\n",(0,s.jsx)(i.p,{children:"Deploy your optimized model with exceptional performance on CPUs using Neural Magic's DeepSparse:"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)("b",{children:"CPU-Optimized Performance:"})," DeepSparse harnesses the potential of sparsity to deliver GPU-level performance on commodity CPUs, maximizing hardware utilization."]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)("b",{children:"Seamless Integration:"})," Deploy easily, as DeepSparse smoothly integrates into your existing applications, minimizing development overhead."]}),"\n"]}),"\n",(0,s.jsx)(i.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsx)(i.p,{children:"Ready to revolutionize your deep learning workflow? Dive into our detailed guides and documentation:"}),"\n",(0,s.jsx)(i.h3,{id:"sections",children:"Sections"}),"\n",(0,s.jsx)(a,{items:["get-started/index","guides/index","products/index","details/index"]}),"\n",(0,s.jsx)(i.h3,{id:"tasks",children:"Tasks"}),"\n",(0,s.jsx)(a,{items:["llms/index","computer-vision/index","nlp/index"]}),"\n",(0,s.jsx)("br",{}),"\n",(0,s.jsx)(i.hr,{}),"\n",(0,s.jsxs)(i.p,{children:["\u2705 ",(0,s.jsx)("b",{children:"Connect:"})," Join our ",(0,s.jsx)(i.a,{href:"https://join.slack.com/t/discuss-neuralmagic/shared_invite/zt-q1a1cnvo-YBoICSIw3L1dmQpjBeDurQ",children:"Slack community"})," for support."]}),"\n",(0,s.jsxs)(i.p,{children:["\u2705 ",(0,s.jsx)("b",{children:"Subscirbe"})," Stay informed with our regular ",(0,s.jsx)(i.a,{href:"https://neuralmagic.com/deep-sparse-community/#subscribe",children:"email updates"}),"."]}),"\n",(0,s.jsxs)(i.p,{children:["\u2705 ",(0,s.jsx)("b",{children:"Contribute:"})," Shape the future of Neural Magic on ",(0,s.jsx)(i.a,{href:"https://github.com/neuralmagic",children:"GitHub"})," (\u2b50's appreciated!)."]}),"\n",(0,s.jsxs)(i.p,{children:["\u2705 ",(0,s.jsx)("b",{children:"Feedback:"})," Help us refine our ",(0,s.jsx)(i.a,{href:"https://github.com/neuralmagic/docs",children:"documentation"}),"."]})]})}function p(e={}){const{wrapper:i}={...(0,o.a)(),...e.components};return i?(0,s.jsx)(i,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8825:(e,i,n)=>{n.d(i,{Z:()=>s});const s=n.p+"assets/images/nm-flows-55d56c0695a30bf9ecb716ea98977a95.png"},1151:(e,i,n)=>{n.d(i,{Z:()=>r,a:()=>t});var s=n(7294);const o={},a=s.createContext(o);function t(e){const i=s.useContext(a);return s.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function r(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:t(e.components),s.createElement(a.Provider,{value:i},e.children)}}}]);