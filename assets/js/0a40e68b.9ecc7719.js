"use strict";(self.webpackChunkdocs_neuralmagic_com=self.webpackChunkdocs_neuralmagic_com||[]).push([[9517],{7021:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>l,contentTitle:()=>a,default:()=>p,frontMatter:()=>t,metadata:()=>r,toc:()=>c});var s=n(4848),o=n(8453);const t={slug:"/",tags:["neural-magic","deep-learning","model-optimization","sparsification","cpu-deployment"],keywords:["Neural Magic","deep learning optimization","CPU inference","sparse models","SparseML","DeepSparse"],sidebar_label:"Home",title:"What is Neural Magic?",description:"Neural Magic empowers you to optimize and deploy deep learning models on CPUs with GPU-class performance. Unlock efficiency, accessibility, and cost savings with our software solutions.",sidebar_position:0},a="Neural Magic Documentation",r={id:"home",title:"What is Neural Magic?",description:"Neural Magic empowers you to optimize and deploy deep learning models on CPUs with GPU-class performance. Unlock efficiency, accessibility, and cost savings with our software solutions.",source:"@site/docs/home.mdx",sourceDirName:".",slug:"/",permalink:"/docs-v2/next/",draft:!1,unlisted:!1,editUrl:"https://github.com/neuralmagic/docs-v2/tree/main/docs/home.mdx",tags:[{label:"neural-magic",permalink:"/docs-v2/next/tags/neural-magic"},{label:"deep-learning",permalink:"/docs-v2/next/tags/deep-learning"},{label:"model-optimization",permalink:"/docs-v2/next/tags/model-optimization"},{label:"sparsification",permalink:"/docs-v2/next/tags/sparsification"},{label:"cpu-deployment",permalink:"/docs-v2/next/tags/cpu-deployment"}],version:"current",sidebarPosition:0,frontMatter:{slug:"/",tags:["neural-magic","deep-learning","model-optimization","sparsification","cpu-deployment"],keywords:["Neural Magic","deep learning optimization","CPU inference","sparse models","SparseML","DeepSparse"],sidebar_label:"Home",title:"What is Neural Magic?",description:"Neural Magic empowers you to optimize and deploy deep learning models on CPUs with GPU-class performance. Unlock efficiency, accessibility, and cost savings with our software solutions.",sidebar_position:0},sidebar:"autogenerated_docs",next:{title:"Getting Started",permalink:"/docs-v2/next/get-started/"}},l={},c=[{value:"Selecting a Model",id:"selecting-a-model",level:2},{value:"Optimizing a Model",id:"optimizing-a-model",level:2},{value:"Deploying a Model",id:"deploying-a-model",level:2},{value:"Next Steps",id:"next-steps",level:2},{value:"Sections",id:"sections",level:3},{value:"Tasks",id:"tasks",level:3}];function d(e){const i={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",hr:"hr",img:"img",li:"li",p:"p",ul:"ul",...(0,o.R)(),...e.components},{DocCardList:t}=i;return t||function(e,i){throw new Error("Expected "+(i?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("DocCardList",!0),(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(i.h1,{id:"neural-magic-documentation",children:"Neural Magic Documentation"}),"\n",(0,s.jsx)(i.p,{children:"Neural Magic is a leader in machine learning model optimization and inference acceleration on the hardware of your choice, CPU or GPU. Our software makes your deployments fast and efficient, and your machine learning practice manageable."}),"\n",(0,s.jsxs)(i.admonition,{title:"FEATURED DEVELOPER HIGHLIGHTS",type:"tip",children:[(0,s.jsx)(i.p,{children:(0,s.jsx)(i.em,{children:"Keep tabs on our innovation with resources, examples, news, and more:"})}),(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:["Blog: ",(0,s.jsx)(i.a,{href:"https://neuralmagic.com/blog/bringing-the-neural-magic-to-gpus/",children:"Neural Magic Leaps Into GPU Acceleration"})]}),"\n",(0,s.jsxs)(i.li,{children:["New community repo for GPU inferencing: ",(0,s.jsx)(i.a,{href:"https://github.com/neuralmagic/nm-vllm",children:(0,s.jsx)(i.code,{children:"nm-vllm"})})]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.a,{href:"https://github.com/neuralmagic/examples/tree/main/notebooks/marlin-nm-vllm",children:"Notebook"}),": Quantize LLMs to 4-bit weights, deploy them with Marlin, inside of ",(0,s.jsx)(i.code,{children:"nm-vllm"}),"!"]}),"\n"]})]}),"\n",(0,s.jsxs)(i.p,{children:[(0,s.jsx)(i.em,{children:"Example CPU Workflow"}),"\n",(0,s.jsx)(i.img,{alt:"Neural Magic Flows",src:n(9262).A+"",width:"1710",height:"1155"})]}),"\n",(0,s.jsx)(i.h2,{id:"selecting-a-model",children:"Selecting a Model"}),"\n",(0,s.jsx)(i.p,{children:"Start by choosing the ideal model for your project:"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)("b",{children:"Neural Magic's Model Repositories:"})," Discover a vast selection of pre-sparsified models across popular use cases in our ",(0,s.jsx)(i.a,{href:"https://sparsezoo.neuralmagic.com/",children:"SparseZoo"})," and ",(0,s.jsx)(i.a,{href:"https://huggingface.co/neuralmagic",children:"Hugging Face"})," repositories. These models are ready for immediate, high-performance deployment."]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)("b",{children:"Custom Models:"})," Easily integrate your PyTorch or ONNX models into Neural Magic's workflow, applying cutting-edge optimization and deployment techniques tailored to your specific needs."]}),"\n"]}),"\n",(0,s.jsx)(i.h2,{id:"optimizing-a-model",children:"Optimizing a Model"}),"\n",(0,s.jsx)(i.p,{children:"Achieve unmatched model efficiency with Neural Magic's SparseML. This powerful toolkit leverages state-of-the-art research to streamline your optimization process:"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)("b",{children:"Advanced Sparsification:"})," Employ sophisticated pruning and quantization strategies to shrink model size and boost inference speed."]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)("b",{children:"User-Friendly Approach:"}),"  SparseML is intuitive and accessible, empowering users at all levels to apply advanced optimization techniques effortlessly."]}),"\n"]}),"\n",(0,s.jsx)(i.h2,{id:"deploying-a-model",children:"Deploying a Model"}),"\n",(0,s.jsx)(i.p,{children:"Deploy your optimized model with exceptional performance on CPUs using Neural Magic's DeepSparse:"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)("b",{children:"CPU-Optimized Performance:"})," DeepSparse harnesses the potential of sparsity to deliver GPU-level performance on commodity CPUs, maximizing hardware utilization."]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)("b",{children:"Seamless Integration:"})," Deploy easily, as DeepSparse smoothly integrates into your existing applications, minimizing development overhead."]}),"\n"]}),"\n",(0,s.jsx)(i.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsx)(i.p,{children:"Ready to revolutionize your deep learning workflow? Dive into our detailed guides and documentation:"}),"\n",(0,s.jsx)(i.h3,{id:"sections",children:"Sections"}),"\n",(0,s.jsx)(t,{items:["get-started/index","guides/index","products/index","details/index"]}),"\n",(0,s.jsx)(i.h3,{id:"tasks",children:"Tasks"}),"\n",(0,s.jsx)(t,{items:["llms/index","computer-vision/index","nlp/index"]}),"\n",(0,s.jsx)("br",{}),"\n",(0,s.jsx)(i.hr,{}),"\n",(0,s.jsxs)(i.p,{children:["\u2705 ",(0,s.jsx)("b",{children:"Connect:"})," Join our ",(0,s.jsx)(i.a,{href:"https://join.slack.com/t/discuss-neuralmagic/shared_invite/zt-q1a1cnvo-YBoICSIw3L1dmQpjBeDurQ",children:"Slack community"})," to meet like-minded ML practitioners."]}),"\n",(0,s.jsxs)(i.p,{children:["\u2705 ",(0,s.jsx)("b",{children:"Subscribe:"})," Stay informed with our regular ",(0,s.jsx)(i.a,{href:"https://neuralmagic.com/deep-sparse-community/#subscribe",children:"email updates"}),"."]}),"\n",(0,s.jsxs)(i.p,{children:["\u2705 ",(0,s.jsx)("b",{children:"Contribute:"})," Shape the future of Neural Magic on ",(0,s.jsx)(i.a,{href:"https://github.com/neuralmagic",children:"GitHub"})," (\u2b50s appreciated!)."]}),"\n",(0,s.jsxs)(i.p,{children:["\u2705 ",(0,s.jsx)("b",{children:"Feedback:"})," Help us refine our ",(0,s.jsx)(i.a,{href:"https://github.com/neuralmagic/docs",children:"documentation"}),"."]})]})}function p(e={}){const{wrapper:i}={...(0,o.R)(),...e.components};return i?(0,s.jsx)(i,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},9262:(e,i,n)=>{n.d(i,{A:()=>s});const s=n.p+"assets/images/nm-flows-55d56c0695a30bf9ecb716ea98977a95.png"},8453:(e,i,n)=>{n.d(i,{R:()=>a,x:()=>r});var s=n(6540);const o={},t=s.createContext(o);function a(e){const i=s.useContext(t);return s.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function r(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:a(e.components),s.createElement(t.Provider,{value:i},e.children)}}}]);