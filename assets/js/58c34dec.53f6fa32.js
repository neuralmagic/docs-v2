"use strict";(self.webpackChunkdocs_neuralmagic_com=self.webpackChunkdocs_neuralmagic_com||[]).push([[7301],{3901:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>c,frontMatter:()=>o,metadata:()=>r,toc:()=>d});var a=t(5893),s=t(1151);const o={tags:["Neural Magic","DeepSparse","SparseZoo","SparseML","AI Deployment","Model Optimization"],keywords:["Neural Network Deployment","Sparsity","Performance Optimization","AI Inference","Model Benchmarking"],description:"A comprehensive guide for deploying neural networks with Neural Magic\u2019s DeepSparse, SparseZoo, and SparseML, focusing on text generation and object detection.",sidebar_label:"Deploy",sidebar_position:2},i="Deployment",r={id:"get-started/deploy",title:"Deployment",description:"A comprehensive guide for deploying neural networks with Neural Magic\u2019s DeepSparse, SparseZoo, and SparseML, focusing on text generation and object detection.",source:"@site/docs/get-started/deploy.mdx",sourceDirName:"get-started",slug:"/get-started/deploy",permalink:"/next/get-started/deploy",draft:!1,unlisted:!1,editUrl:"https://github.com/neuralmagic/docs/docs/get-started/deploy.mdx",tags:[{label:"Neural Magic",permalink:"/next/tags/neural-magic"},{label:"DeepSparse",permalink:"/next/tags/deep-sparse"},{label:"SparseZoo",permalink:"/next/tags/sparse-zoo"},{label:"SparseML",permalink:"/next/tags/sparse-ml"},{label:"AI Deployment",permalink:"/next/tags/ai-deployment"},{label:"Model Optimization",permalink:"/next/tags/model-optimization"}],version:"current",sidebarPosition:2,frontMatter:{tags:["Neural Magic","DeepSparse","SparseZoo","SparseML","AI Deployment","Model Optimization"],keywords:["Neural Network Deployment","Sparsity","Performance Optimization","AI Inference","Model Benchmarking"],description:"A comprehensive guide for deploying neural networks with Neural Magic\u2019s DeepSparse, SparseZoo, and SparseML, focusing on text generation and object detection.",sidebar_label:"Deploy",sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"SparseZoo",permalink:"/next/get-started/install/sparsezoo"},next:{title:"Finetune",permalink:"/next/get-started/finetune"}},l={},d=[{value:"Generative AI - LLMs",id:"generative-ai---llms",level:2},{value:"Pipeline",id:"pipeline",level:3},{value:"Server",id:"server",level:3},{value:"CV - Object Detection",id:"cv---object-detection",level:2},{value:"Pipeline",id:"pipeline-1",level:3},{value:"Server",id:"server-1",level:3}];function p(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",hr:"hr",li:"li",p:"p",pre:"pre",ul:"ul",...(0,s.a)(),...e.components},{Details:t,TabItem:o,Tabs:i}=n;return t||h("Details",!0),o||h("TabItem",!0),i||h("Tabs",!0),(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.h1,{id:"deployment",children:"Deployment"}),"\n",(0,a.jsx)(n.p,{children:"This guide provides detailed instructions for deploying neural networks using Neural Magic's suite, including DeepSparse, SparseZoo, and SparseML.\nYou'll learn about the key processes such as benchmarking, pipeline creation, and server setup, focusing on text generation and object detection models."}),"\n",(0,a.jsx)(n.h2,{id:"generative-ai---llms",children:"Generative AI - LLMs"}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsxs)(n.p,{children:["Ensure you've installed the required packages and dependencies for Generative AI as outlined in the ",(0,a.jsx)(n.a,{href:"./install#generative-ai",children:"Install Guide"}),"."]})}),"\n",(0,a.jsx)(n.p,{children:"This section covers deploying large language models (LLMs) with DeepSparse including benchmarking, pipeline creation, and server setup utilizing a pre-sparsified model from the SparseZoo."}),"\n",(0,a.jsx)(n.p,{children:"The examples below use a sparse, quantized Llama 2 7b chat model to demonstrate the deployment process.\nThe model is referenced by the following SparseZoo stub for use in the Neural Magic suite:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-text",children:"zoo:llama2-7b-ultrachat200k_llama2_pretrain-pruned50_quantized\n"})}),"\n",(0,a.jsxs)(n.p,{children:["For other models that work with these examples, browse through the ",(0,a.jsx)(n.a,{href:"https://sparsezoo.neuralmagic.com/?modelSet=generative_ai",children:"Generative AI models in the SparseZoo"})," to find one that fits your needs."]}),"\n",(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Benchmarking"}),(0,a.jsx)(n.p,{children:"Benchmarking is an optional step that demonstrates how to validate the performance for both dense and sparsified models, while showcasing the benefits of sparsity in the process."}),(0,a.jsx)(n.p,{children:"First benchmark an unoptimized version of the model to establish the baseline.\nThe SparseZoo stub for the dense model is:"}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-text",children:"zoo:llama2-7b-ultrachat200k_llama2_pretrain-base\n"})}),(0,a.jsx)(n.p,{children:"Utilizing this stub, benchmark the dense, baseline model with the following command:"}),(0,a.jsxs)(i,{children:[(0,a.jsx)(o,{value:"bash",label:"Bash",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'deepsparse.benchmark "zoo:llama2-7b-ultrachat200k_llama2_pretrain-base"\n\n# <output>\n# TODO: add output\n# </output>\n'})})}),(0,a.jsx)(o,{value:"python",label:"Python",children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from deepsparse import benchmark\n\nresult = benchmark("zoo:llama2-7b-ultrachat200k_llama2_pretrain-base")\nprint(result)\n\n# <output>\n# TODO: add output\n# </output>\n'})})})]}),(0,a.jsxs)(n.p,{children:["As seen in the output, the baseline model achieves a throughput of ",(0,a.jsx)(n.code,{children:"x"})," tokens per second on a 4-core Intel CPU."]}),(0,a.jsx)(n.p,{children:"Next, benchmark the sparsified model to compare the performance:"}),(0,a.jsxs)(i,{children:[(0,a.jsx)(o,{value:"bash",label:"Bash",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'deepsparse.benchmark "zoo:llama2-7b-ultrachat200k_llama2_pretrain-pruned50_quantized"\n\n# <output>\n# TODO: add output\n# </output>\n'})})}),(0,a.jsx)(o,{value:"python",label:"Python",children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from deepsparse import benchmark\n\nresult = benchmark("zoo:llama2-7b-ultrachat200k_llama2_pretrain-pruned50_quantized")\nprint(result)\n\n# <output>\n# TODO: add output\n# </output>\n'})})})]}),(0,a.jsxs)(n.p,{children:["The sparsified model achieves a throughput of ",(0,a.jsx)(n.code,{children:"y"})," tokens per second on the same CPU, which is ",(0,a.jsx)(n.code,{children:"z"})," times faster than the baseline model!"]})]}),"\n",(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Evaluating"}),(0,a.jsx)(n.p,{children:"This is an optional step that demonstrates how to evaluate a model on a given dataset or set of datasets using DeepSparse to validate and compare the accuracies of dense and sparsified models."}),(0,a.jsx)(n.p,{children:"First, evaluate the baseline model to establish the accuracy baseline.\nThe SparseZoo stub for the dense model is:"}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-text",children:"zoo:llama2-7b-ultrachat200k_llama2_pretrain-base\n"})}),(0,a.jsxs)(n.p,{children:["Utilizing this stub, evaluate the dense, baseline model utilizing the ",(0,a.jsx)(n.code,{children:"lm-eval-harness"})," with the following command:"]}),(0,a.jsxs)(i,{children:[(0,a.jsx)(o,{value:"bash",label:"Bash",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'deepsparse.evaluate "zoo:llama2-7b-ultrachat200k_llama2_pretrain-pruned50_quantized" --integration lm\n\n# <output>\n# TODO: add output\n# </output>\n'})})}),(0,a.jsx)(o,{value:"python",label:"Python",children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from deepsparse import evaluate\n\nresult = evaluate("zoo:llama2-7b-ultrachat200k_llama2_pretrain-pruned50_quantized", integration="lm")\nprint(result)\n\n# <output>\n# TODO: add output\n# </output>\n'})})})]}),(0,a.jsxs)(n.p,{children:["As seen in the output, the baseline model achieves a perplexity of ",(0,a.jsx)(n.code,{children:"x"})," on the validation dataset."]}),(0,a.jsx)(n.p,{children:"Next, evaluate the sparsified model to compare the accuracy:"}),(0,a.jsxs)(i,{children:[(0,a.jsx)(o,{value:"bash",label:"Bash",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'deepsparse.evaluate "zoo:llama2-7b-ultrachat200k_llama2_pretrain-pruned50_quantized" --integration lm\n\n# <output>\n# TODO: add output\n# </output>\n'})})}),(0,a.jsx)(o,{value:"python",label:"Python",children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from deepsparse import evaluate\n\nresult = evaluate("zoo:llama2-7b-ultrachat200k_llama2_pretrain-pruned50_quantized", integration="lm")\nprint(result)\n\n# <output>\n# TODO: add output\n# </output>\n'})})})]}),(0,a.jsxs)(n.p,{children:["The sparsified model achieves a perplexity of ",(0,a.jsx)(n.code,{children:"y"})," on the validation dataset, which is within ",(0,a.jsx)(n.code,{children:"z"})," of the baseline model!"]})]}),"\n",(0,a.jsx)(n.h3,{id:"pipeline",children:"Pipeline"}),"\n",(0,a.jsx)(n.p,{children:"DeepSparse pipelines for LLMs match the Hugging Face Transformers Python API, allowing for familiarity and easy integration with existing codebases.\nTo create a text generation pipeline for the example model and generate text, utilize the following code:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from deepsparse import TextGeneration\n\npipeline = TextGeneration("zoo:llama2-7b-ultrachat200k_llama2_pretrain-pruned50_quantized")\nresult = pipeline("Neural Magic is")\nprint(result)\n\n# <output>\n# TODO: add output\n# </output>\n'})}),"\n",(0,a.jsx)(n.p,{children:"As seen in the output, the pipeline generates text based on the input prompt."}),"\n",(0,a.jsx)(n.h3,{id:"server",children:"Server"}),"\n",(0,a.jsx)(n.p,{children:"The DeepSparse Server wraps a pipeline in a REST API, allowing for easy deployment and inference.\nFor generative LLMS, the server supports the OpenAI inference standards, allowing for familiarity and easy integration with existing codebases."}),"\n",(0,a.jsx)(n.p,{children:"To create a DeepSparse TextGeneration server that will run on port 5543 (default) with the OpenAI specs, utilize the following code:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'deepsparse.server "zoo:llama2-7b-ultrachat200k_llama2_pretrain-pruned50_quantized" --integration openai\n\n# <output>\n# TODO: add output\n# </output>\n'})}),"\n",(0,a.jsxs)(n.p,{children:["Now with the server running, you can send an HTTP request that conforms to the OpenAI spec to generate text.\nBelow are examples for using ",(0,a.jsx)(n.code,{children:"curl"})," and ",(0,a.jsx)(n.code,{children:"python"})," to send a request to the server:"]}),"\n",(0,a.jsxs)(i,{children:[(0,a.jsx)(o,{value:"bash",label:"Bash",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'curl http://localhost:5543/v1/chat/completions \\\n    -H "Content-Type: application/json" \\\n    -d \'{\n        "model": "zoo:llama2-7b-ultrachat200k_llama2_pretrain-pruned50_quantized",\n        "messages": "Neural Magic is",\n        "stream": true\n    }\'\n\n# <output>\n# TODO: add output\n# </output>\n'})})}),(0,a.jsx)(o,{value:"python",label:"Python",children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import openai\n\nopenai.api_key = "EMPTY"\nopenai.api_base = "http://localhost:5543/v1"\n\nstream = False\ncompletion = openai.ChatCompletion.create(\n    messages="Neural Magic is",\n    stream=stream,\n    max_tokens=30,\n    model="zoo:llama2-7b-ultrachat200k_llama2_pretrain-pruned50_quantized",\n)\n\nif stream:\n    for c in completion:\n        print(c)\nelse:\n    print(completion)\n\n# <output>\n# TODO: add output\n# </output>\n'})})})]}),"\n",(0,a.jsx)(n.p,{children:"As seen in the output, the server generates text based on the input prompt."}),"\n",(0,a.jsx)(n.p,{children:"To complete the sections for Computer Vision (CV) - Object Detection in the deployment guide, let's provide instructions and examples tailored for object detection models using Neural Magic's suite."}),"\n",(0,a.jsx)(n.h2,{id:"cv---object-detection",children:"CV - Object Detection"}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsxs)(n.p,{children:["Ensure you've installed the necessary packages and dependencies for CV - Object Detection as outlined in the ",(0,a.jsx)(n.a,{href:"./install#object-detection",children:"Install Guide"}),"."]})}),"\n",(0,a.jsx)(n.p,{children:"This section covers deploying object detection models with DeepSparse including benchmarking, pipeline creation, and server setup utilizing a pre-sparsified model from the SparseZoo."}),"\n",(0,a.jsx)(n.p,{children:"The examples below use a sparse, quantized YOLOv8 L model to demonstrate the deployment process.\nThe model is referenced by the following SparseZoo stub for use in the Neural Magic suite:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-text",children:"zoo:yolov8-l-coco-pruned85_quantized\n"})}),"\n",(0,a.jsxs)(n.p,{children:["For other models that work with these examples, browse through the ",(0,a.jsx)(n.a,{href:"https://sparsezoo.neuralmagic.com/?architectures=yolov8&datasets=coco&tasks=detection&modelSet=computer_vision",children:"CV - Object Detection YOLOv8 models in the SparseZoo"})," to find one that fits your needs."]}),"\n",(0,a.jsxs)(n.p,{children:["Additionally, the Pipeline and Server examples expect an image to be located at ",(0,a.jsx)(n.code,{children:"image.jpg"})," in the current working directory.\nTo download an example image, run the following command:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"wget -O image.jpg https://raw.githubusercontent.com/neuralmagic/deepsparse/main/src/deepsparse/yolo/sample_images/basilica.jpg\n"})}),"\n",(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Benchmarking"}),(0,a.jsx)(n.p,{children:"Benchmarking is an optional step that demonstrates how to validate the performance for both dense and sparsified models, while showcasing the benefits of sparsity in the process."}),(0,a.jsx)(n.p,{children:"First benchmark an unoptimized version of the model to establish the baseline.\nThe SparseZoo stub for the dense model is:"}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-text",children:"zoo:yolov8-l-coco-base\n"})}),(0,a.jsx)(n.p,{children:"Utilizing this stub, benchmark the dense, baseline model with the following command:"}),(0,a.jsxs)(i,{children:[(0,a.jsx)(o,{value:"bash",label:"Bash",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'deepsparse.benchmark "zoo:yolov8-l-coco-base"\n\n# <output>\n# TODO: add output\n# </output>\n'})})}),(0,a.jsx)(o,{value:"python",label:"Python",children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from deepsparse import benchmark\n\nresult = benchmark("zoo:yolov8-l-coco-base")\nprint(result)\n\n# <output>\n# TODO: add output\n# </output>\n'})})})]}),(0,a.jsxs)(n.p,{children:["As seen in the output, the baseline model achieves a throughput of ",(0,a.jsx)(n.code,{children:"x"})," images per second on a 4-core Intel CPU."]}),(0,a.jsx)(n.p,{children:"Next, benchmark the sparsified model to compare the performance:"}),(0,a.jsxs)(i,{children:[(0,a.jsx)(o,{value:"bash",label:"Bash",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'deepsparse.benchmark "zoo:yolov8-l-coco-pruned85_quantized"\n\n# <output>\n# TODO: add output\n# </output>\n'})})}),(0,a.jsx)(o,{value:"python",label:"Python",children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from deepsparse import benchmark\n\nresult = benchmark("zoo:yolov8-l-coco-pruned85_quantized")\nprint(result)\n\n# <output>\n# TODO: add output\n# </output>\n'})})})]}),(0,a.jsxs)(n.p,{children:["The sparsified model achieves a throughput of ",(0,a.jsx)(n.code,{children:"y"})," images per second on the same CPU, which is ",(0,a.jsx)(n.code,{children:"z"})," times faster than the baseline model!"]})]}),"\n",(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Evaluating"}),(0,a.jsx)(n.p,{children:"This is an optional step that demonstrates how to evaluate a model on a given dataset or set of datasets using DeepSparse to validate and compare the accuracies of dense and sparsified models."}),(0,a.jsx)(n.p,{children:"First, evaluate the baseline model to establish the accuracy baseline.\nThe SparseZoo stub for the dense model is:"}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-text",children:"zoo:yolov8-l-coco-base\n"})}),(0,a.jsx)(n.p,{children:"Utilizing this stub, evaluate the dense, baseline model on the COCO128 dataset (default) with the following command:"}),(0,a.jsx)(i,{children:(0,a.jsx)(o,{value:"bash",label:"Bash",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'deepsparse.yolov8.eval --model_path "zoo:yolov8-l-coco-base"\n\n# <output>\n# TODO: add output\n# </output>\n'})})})}),(0,a.jsxs)(n.p,{children:["As seen in the output, the baseline model achieves a mAP of ",(0,a.jsx)(n.code,{children:"x"})," on the validation dataset."]}),(0,a.jsx)(n.p,{children:"Next, evaluate the sparsified model to compare the accuracy:"}),(0,a.jsx)(i,{children:(0,a.jsx)(o,{value:"bash",label:"Bash",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'deepsparse.yolov8.eval --model_path "zoo:yolov8-l-coco-pruned85_quantized"\n\n# <output>\n# TODO: add output\n# </output>\n'})})})}),(0,a.jsxs)(n.p,{children:["The sparsified model achieves a mAP of ",(0,a.jsx)(n.code,{children:"y"})," on the validation dataset, which is within ",(0,a.jsx)(n.code,{children:"z"})," of the baseline model!"]})]}),"\n",(0,a.jsx)(n.h3,{id:"pipeline-1",children:"Pipeline"}),"\n",(0,a.jsx)(n.p,{children:"DeepSparse pipelines for YOLOv8 models accept an image or images as inputs and return a list of bounding boxes and their associated classes and confidences.\nTo create an object detection pipeline for the example model and process an image, utilize the following code:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from deepsparse import Pipeline\n\npipeline = Pipeline.create(task="yolov8", model_path="zoo:yolov8-l-coco-pruned85_quantized")\nresult = pipeline("basilica.jpg")\nprint(result)\n\n# <output>\n# TODO: add output\n# </output>\n'})}),"\n",(0,a.jsx)(n.p,{children:"This code initializes an object detection pipeline and processes an image."}),"\n",(0,a.jsx)(n.h3,{id:"server-1",children:"Server"}),"\n",(0,a.jsx)(n.p,{children:"The DeepSparse Server wraps a pipeline in a REST API, allowing for easy deployment and inference.\nFor object detection models, the server supports the MLServer inference standards, allowing for familiarity and easy integration with existing codebases."}),"\n",(0,a.jsx)(n.p,{children:"To create a DeepSparse Pipeline server that will run on port 5543 (default) with the MLServer specs, utilize the following code:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'deepsparse.server "zoo:yolov8-l-coco-pruned85_quantized"\n'})}),"\n",(0,a.jsxs)(n.p,{children:["Now with the server running, you can send an HTTP request that conforms to the MLServer spec to process an image.\nBelow are examples for using ",(0,a.jsx)(n.code,{children:"curl"})," and ",(0,a.jsx)(n.code,{children:"python"})," to send a request to the server:"]}),"\n",(0,a.jsxs)(i,{children:[(0,a.jsx)(o,{value:"bash",label:"Bash",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'curl -X POST http://localhost:5543/predict \\\n    -H "Content-Type: application/json" \\\n    -d \'{"inputs": ["path/to/image.jpg"]}\'\n\n# <output>\n# TODO: add output\n# </output>\n'})})}),(0,a.jsx)(o,{value:"python",label:"Python",children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import requests\n\nresponse = requests.post(\n    "http://localhost:5543/predict",\n    json={"inputs": ["path/to/image.jpg"]}\n)\n\n# <output>\n# TODO: add output\n# </output>\n'})})})]}),"\n",(0,a.jsx)(n.p,{children:"As seen in the output, the server processes the image and returns a list of bounding boxes and their associated classes and confidences."}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.p,{children:"For more information on the example tasks in this guide, other supported tasks, and custom integrations dive into the following resources:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"../generative-ai",children:"Generative AI"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"../computer-vision",children:"Computer Vision"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"../nlp",children:"Natural Language Processing"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"../custom-integrations",children:"Custom Integrations"})}),"\n"]})]})}function c(e={}){const{wrapper:n}={...(0,s.a)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(p,{...e})}):p(e)}function h(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}},1151:(e,n,t)=>{t.d(n,{Z:()=>r,a:()=>i});var a=t(7294);const s={},o=a.createContext(s);function i(e){const n=a.useContext(o);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),a.createElement(o.Provider,{value:n},e.children)}}}]);