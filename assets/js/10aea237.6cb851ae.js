"use strict";(self.webpackChunkdocs_neuralmagic_com=self.webpackChunkdocs_neuralmagic_com||[]).push([[8724],{8828:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>p,frontMatter:()=>s,metadata:()=>r,toc:()=>d});var i=n(5893),a=n(1151);const s={tags:["getting started","installation","deployment","optimization"],keywords:["Neural Magic","setup","SparseML","DeepSparse","sparsification"],title:"Getting Started",description:"Launch your Neural Magic journey with essential setup, installation guides, and foundational concepts.",sidebar_position:1},o="Getting Started with Neural Magic",r={id:"get-started/index",title:"Getting Started",description:"Launch your Neural Magic journey with essential setup, installation guides, and foundational concepts.",source:"@site/docs/get-started/index.mdx",sourceDirName:"get-started",slug:"/get-started/",permalink:"/docs-v2/get-started/",draft:!1,unlisted:!1,editUrl:"https://github.com/neuralmagic/docs-v2/tree/main/docs/get-started/index.mdx",tags:[{label:"getting started",permalink:"/docs-v2/tags/getting-started"},{label:"installation",permalink:"/docs-v2/tags/installation"},{label:"deployment",permalink:"/docs-v2/tags/deployment"},{label:"optimization",permalink:"/docs-v2/tags/optimization"}],version:"current",sidebarPosition:1,frontMatter:{tags:["getting started","installation","deployment","optimization"],keywords:["Neural Magic","setup","SparseML","DeepSparse","sparsification"],title:"Getting Started",description:"Launch your Neural Magic journey with essential setup, installation guides, and foundational concepts.",sidebar_position:1},sidebar:"autogenerated_docs",previous:{title:"Home",permalink:"/docs-v2/"},next:{title:"Install",permalink:"/docs-v2/get-started/install/"}},l={},d=[{value:"Installation",id:"installation",level:2},{value:"Deploy a Model",id:"deploy-a-model",level:2},{value:"Optimize a Model",id:"optimize-a-model",level:2},{value:"Fine-tune a Sparse Model",id:"fine-tune-a-sparse-model",level:2},{value:"Transfer a Sparse Model",id:"transfer-a-sparse-model",level:2}];function c(e){const t={a:"a",h1:"h1",h2:"h2",hr:"hr",p:"p",...(0,a.a)(),...e.components},{DocCardList:n}=t;return n||function(e,t){throw new Error("Expected "+(t?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("DocCardList",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.h1,{id:"getting-started-with-neural-magic",children:"Getting Started with Neural Magic"}),"\n",(0,i.jsx)(t.p,{children:"Ready to optimize and deploy deep learning models with greater efficiency?\nThis guide provides the essential steps to get up and running with Neural Magic's powerful software suite.\nSpecifically, you'll learn how to install our key products, deploy an LLM, and create your sparsified LLMs."}),"\n",(0,i.jsx)(t.h2,{id:"installation",children:"Installation"}),"\n",(0,i.jsx)(t.p,{children:"Ensure a seamless start by installing Neural Magic's core components and configuring your environment for model optimization and deployment.\nWe'll guide you through managing dependencies and tailoring the setup for your specific use case."}),"\n",(0,i.jsx)(n,{items:["get-started/install/index"]}),"\n",(0,i.jsx)(t.h2,{id:"deploy-a-model",children:"Deploy a Model"}),"\n",(0,i.jsx)(t.p,{children:"Discover how to deploy pre-sparsified LLMs for accelerated text generation and reduced resource demands. Unlock cost-effective AI applications through the power of CPU-optimized LLM deployment."}),"\n",(0,i.jsx)(n,{items:["get-started/deploy"]}),"\n",(0,i.jsx)(t.h2,{id:"optimize-a-model",children:"Optimize a Model"}),"\n",(0,i.jsx)(t.p,{children:"Learn how to apply state-of-the-art sparsification to significantly reduce the footprint and increase the inference speed of your LLMs quickly utilizing post-training techniques."}),"\n",(0,i.jsx)(n,{items:["get-started/optimize"]}),"\n",(0,i.jsx)(t.h2,{id:"fine-tune-a-sparse-model",children:"Fine-tune a Sparse Model"}),"\n",(0,i.jsx)(t.p,{children:"Refine your sparsified LLM through fine-tuning to improve its performance and accuracy for your specific use case."}),"\n",(0,i.jsx)(n,{items:["get-started/fine-tune"]}),"\n",(0,i.jsx)(t.h2,{id:"transfer-a-sparse-model",children:"Transfer a Sparse Model"}),"\n",(0,i.jsx)(t.p,{children:"Transfer a pre-sparsified, foundational LLM to your use case without heavy retraining or model optimization tuning."}),"\n",(0,i.jsx)(n,{items:["get-started/transfer"]}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)(t.hr,{}),"\n",(0,i.jsxs)(t.p,{children:["\ud83d\udd17 ",(0,i.jsx)("b",{children:"Let's Get Started!"})," Choose a task above to begin your Neural Magic journey."]}),"\n",(0,i.jsxs)(t.p,{children:["\ud83d\udcda ",(0,i.jsx)("b",{children:"Need Help?"})," Join our ",(0,i.jsx)(t.a,{href:"https://join.slack.com/t/discuss-neuralmagic/shared_invite/zt-q1a1cnvo-YBoICSIw3L1dmQpjBeDurQ",children:"Slack community"})," for support."]}),"\n",(0,i.jsxs)(t.p,{children:["\ud83c\udf1f ",(0,i.jsx)("b",{children:"Shape the Future:"})," Contirbute to our GitHub ",(0,i.jsx)(t.a,{href:"https://github.com/neuralmagic",children:"GitHub repositories"}),"."]})]})}function p(e={}){const{wrapper:t}={...(0,a.a)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},1151:(e,t,n)=>{n.d(t,{Z:()=>r,a:()=>o});var i=n(7294);const a={},s=i.createContext(a);function o(e){const t=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),i.createElement(s.Provider,{value:t},e.children)}}}]);