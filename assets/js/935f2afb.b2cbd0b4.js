"use strict";(self.webpackChunkdocs_neuralmagic_com=self.webpackChunkdocs_neuralmagic_com||[]).push([[8581],{5610:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"nightly","banner":"unreleased","badge":true,"noIndex":false,"className":"docs-version-current","isLast":false,"docsSidebars":{"autogenerated_docs":[{"type":"link","label":"Home","href":"/docs-v2/next/","docId":"home","unlisted":false},{"type":"category","label":"Getting Started","collapsible":true,"collapsed":false,"items":[{"type":"category","label":"Install","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"DeepSparse","href":"/docs-v2/next/get-started/install/deepsparse","docId":"get-started/install/deepsparse","unlisted":false},{"type":"link","label":"SparseML","href":"/docs-v2/next/get-started/install/sparseml","docId":"get-started/install/sparseml","unlisted":false},{"type":"link","label":"SparseZoo","href":"/docs-v2/next/get-started/install/sparsezoo","docId":"get-started/install/sparsezoo","unlisted":false}],"href":"/docs-v2/next/get-started/install/"},{"type":"link","label":"Deploy","href":"/docs-v2/next/get-started/deploy","docId":"get-started/deploy","unlisted":false},{"type":"link","label":"Optimize","href":"/docs-v2/next/get-started/optimize","docId":"get-started/optimize","unlisted":false},{"type":"link","label":"Sparse Fine-Tuning","href":"/docs-v2/next/get-started/finetune","docId":"get-started/finetune","unlisted":false},{"type":"link","label":"Sparse Transfer","href":"/docs-v2/next/get-started/transfer","docId":"get-started/transfer","unlisted":false}],"href":"/docs-v2/next/get-started/"},{"type":"link","label":"Guides","href":"/docs-v2/next/guides/","docId":"guides/index","unlisted":false},{"type":"category","label":"LLMs - Causal Language Modeling","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Serving LLMs","href":"/docs-v2/next/llms/serving-llms","docId":"llms/serving-llms","unlisted":false},{"type":"category","label":"Models","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Hugging Face Hub Models","href":"/docs-v2/next/llms/models/huggingface-models","docId":"llms/models/huggingface-models","unlisted":false},{"type":"link","label":"SparseZoo Models","href":"/docs-v2/next/llms/models/sparsezoo-models","docId":"llms/models/sparsezoo-models","unlisted":false}],"href":"/docs-v2/next/llms/models/"},{"type":"link","label":"Tutorials","href":"/docs-v2/next/llms/tutorials/","docId":"llms/tutorials/index","unlisted":false},{"type":"category","label":"Guides","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Why is Sparsity Important for LLMs?","href":"/docs-v2/next/llms/guides/why-weight-sparsity","docId":"llms/guides/why-weight-sparsity","unlisted":false},{"type":"link","label":"Convert LLMs From Hugging Face","href":"/docs-v2/next/llms/guides/hf-llm-to-deepsparse","docId":"llms/guides/hf-llm-to-deepsparse","unlisted":false},{"type":"link","label":"Compress LLMs With SparseGPT","href":"/docs-v2/next/llms/guides/one-shot-llms-with-sparseml","docId":"llms/guides/one-shot-llms-with-sparseml","unlisted":false},{"type":"link","label":"LLM Serving on Windows","href":"/docs-v2/next/llms/guides/llm-serving-on-windows","docId":"llms/guides/llm-serving-on-windows","unlisted":false}],"href":"/docs-v2/next/llms/guides/"}],"href":"/docs-v2/next/llms/"},{"type":"category","label":"Computer Vision","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Object Detection","href":"/docs-v2/next/computer-vision/object-detection/","docId":"computer-vision/object-detection/index","unlisted":false},{"type":"link","label":"Image Segmentation","href":"/docs-v2/next/computer-vision/image-segmentation/","docId":"computer-vision/image-segmentation/index","unlisted":false},{"type":"link","label":"Image Classification","href":"/docs-v2/next/computer-vision/image-classification/","docId":"computer-vision/image-classification/index","unlisted":false}],"href":"/docs-v2/next/computer-vision/"},{"type":"category","label":"Natural Language Processing","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Text Classification","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Getting Started","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Deployment","href":"/docs-v2/next/nlp/text-classification/get-started/deploy","docId":"nlp/text-classification/get-started/deploy","unlisted":false},{"type":"link","label":"Finetune","href":"/docs-v2/next/nlp/text-classification/get-started/finetune","docId":"nlp/text-classification/get-started/finetune","unlisted":false},{"type":"link","label":"Sparsify","href":"/docs-v2/next/nlp/text-classification/get-started/sparsify","docId":"nlp/text-classification/get-started/sparsify","unlisted":false}],"href":"/docs-v2/next/nlp/text-classification/get-started/"},{"type":"link","label":"Models","href":"/docs-v2/next/nlp/text-classification/models/","docId":"nlp/text-classification/models/index","unlisted":false},{"type":"link","label":"Tutorials","href":"/docs-v2/next/nlp/text-classification/tutorials/","docId":"nlp/text-classification/tutorials/index","unlisted":false}],"href":"/docs-v2/next/nlp/text-classification/"},{"type":"category","label":"Token Classification","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Getting Started","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Deployment","href":"/docs-v2/next/nlp/token-classification/get-started/deploy","docId":"nlp/token-classification/get-started/deploy","unlisted":false},{"type":"link","label":"Finetune","href":"/docs-v2/next/nlp/token-classification/get-started/finetune","docId":"nlp/token-classification/get-started/finetune","unlisted":false},{"type":"link","label":"Sparsify","href":"/docs-v2/next/nlp/token-classification/get-started/sparsify","docId":"nlp/token-classification/get-started/sparsify","unlisted":false}],"href":"/docs-v2/next/nlp/token-classification/get-started/"},{"type":"link","label":"Models","href":"/docs-v2/next/nlp/token-classification/models/","docId":"nlp/token-classification/models/index","unlisted":false},{"type":"link","label":"Tutorials","href":"/docs-v2/next/nlp/token-classification/tutorials/","docId":"nlp/token-classification/tutorials/index","unlisted":false}],"href":"/docs-v2/next/nlp/token-classification/"},{"type":"category","label":"Question Answering","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Getting Started","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Deployment","href":"/docs-v2/next/nlp/question-answering/get-started/deploy","docId":"nlp/question-answering/get-started/deploy","unlisted":false},{"type":"link","label":"Finetune","href":"/docs-v2/next/nlp/question-answering/get-started/finetune","docId":"nlp/question-answering/get-started/finetune","unlisted":false},{"type":"link","label":"Sparsify","href":"/docs-v2/next/nlp/question-answering/get-started/sparsify","docId":"nlp/question-answering/get-started/sparsify","unlisted":false}],"href":"/docs-v2/next/nlp/question-answering/get-started/"},{"type":"link","label":"Models","href":"/docs-v2/next/nlp/question-answering/models/","docId":"nlp/question-answering/models/index","unlisted":false},{"type":"link","label":"Tutorials","href":"/docs-v2/next/nlp/question-answering/tutorials/","docId":"nlp/question-answering/tutorials/index","unlisted":false}],"href":"/docs-v2/next/nlp/question-answering/"}],"href":"/docs-v2/next/nlp/"},{"type":"category","label":"Products","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"DeepSparse","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Releases","href":"/docs-v2/next/products/deepsparse/releases","docId":"products/deepsparse/releases","unlisted":false}],"href":"/docs-v2/next/products/deepsparse/"},{"type":"category","label":"SparseML","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Releases","href":"/docs-v2/next/products/sparseml/releases","docId":"products/sparseml/releases","unlisted":false}],"href":"/docs-v2/next/products/sparseml/"},{"type":"category","label":"SparseZoo","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Releases","href":"/docs-v2/next/products/sparsezoo/releases","docId":"products/sparsezoo/releases","unlisted":false}],"href":"/docs-v2/next/products/sparsezoo/"}],"href":"/docs-v2/next/products/"},{"type":"category","label":"Details","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"FAQs","href":"/docs-v2/next/details/faqs","docId":"details/faqs","unlisted":false},{"type":"link","label":"Glossary","href":"/docs-v2/next/details/glossary","docId":"details/glossary","unlisted":false},{"type":"link","label":"Research Papers","href":"/docs-v2/next/details/research-papers","docId":"details/research-papers","unlisted":false}],"href":"/docs-v2/next/details/"}]},"docs":{"computer-vision/image-classification/index":{"id":"computer-vision/image-classification/index","title":"Image Classification","description":"Check out the links on the left to get started!","sidebar":"autogenerated_docs"},"computer-vision/image-segmentation/index":{"id":"computer-vision/image-segmentation/index","title":"Image Segmentation","description":"Check out the links on the left to get started!","sidebar":"autogenerated_docs"},"computer-vision/index":{"id":"computer-vision/index","title":"Computer Vision","description":"Optimize and deploy cutting-edge computer vision models for image classification, object detection, and complex image segmentation tasks.","sidebar":"autogenerated_docs"},"computer-vision/object-detection/index":{"id":"computer-vision/object-detection/index","title":"Object Detection","description":"Check out the links on the left to get started!","sidebar":"autogenerated_docs"},"details/faqs":{"id":"details/faqs","title":"FAQs","description":"General Product FAQs","sidebar":"autogenerated_docs"},"details/glossary":{"id":"details/glossary","title":"Glossary","description":"Terms and Definitions","sidebar":"autogenerated_docs"},"details/index":{"id":"details/index","title":"Details","description":"Explore in-depth tutorials and walkthroughs showcasing best practices for model optimization, deployment, and use-case-specific applications.","sidebar":"autogenerated_docs"},"details/research-papers":{"id":"details/research-papers","title":"Research Papers","description":"return Redirecting...;","sidebar":"autogenerated_docs"},"get-started/deploy":{"id":"get-started/deploy","title":"Deploying LLMs","description":"Deploy large language models (LLMs) for text generation using Neural Magic\'s DeepSparse. This doc includes code examples, performance benchmarking, and server setup.","sidebar":"autogenerated_docs"},"get-started/finetune":{"id":"get-started/finetune","title":"Sparse Fine-Tuning With LLMs","description":"Improve the performance of your large language models (LLMs) through fine-tuning with Neural Magic\'s SparseML. Optimize LLMs for specific tasks while maintaining accuracy.","sidebar":"autogenerated_docs"},"get-started/index":{"id":"get-started/index","title":"Getting Started","description":"Launch your Neural Magic journey with essential setup, installation guides, and foundational concepts.","sidebar":"autogenerated_docs"},"get-started/install/deepsparse":{"id":"get-started/install/deepsparse","title":"Installing DeepSparse","description":"Install DeepSparse, Neural Magic\'s high-performance inference engine, for optimized deep learning model deployment on CPUs.","sidebar":"autogenerated_docs"},"get-started/install/index":{"id":"get-started/install/index","title":"Installation","description":"Step-by-step guides for installing NeuralMagic Products such as DeepSparse, SparseML, and SparseZoo.","sidebar":"autogenerated_docs"},"get-started/install/sparseml":{"id":"get-started/install/sparseml","title":"Installing SparseML","description":"Install SparseML, Neural Magic\'s toolkit for optimizing deep learning models through state-of-the-art sparsification techniques.","sidebar":"autogenerated_docs"},"get-started/install/sparsezoo":{"id":"get-started/install/sparsezoo","title":"Installing SparseZoo","description":"Install SparseZoo, Neural Magic\'s repository of pre-sparsified models, or learn how to access it through SparseML and DeepSparse.","sidebar":"autogenerated_docs"},"get-started/optimize":{"id":"get-started/optimize","title":"Optimizing LLMs","description":"Optimize large language models (LLMs) for efficient inference using one-shot pruning and quantization. Learn how to improve model performance and reduce costs without sacrificing accuracy.","sidebar":"autogenerated_docs"},"get-started/transfer":{"id":"get-started/transfer","title":"Sparse Transferring LLMs","description":"Adapt large language models (LLMs) to new domains and tasks using sparse transfer learning with Neural Magic\'s SparseML. Maintain accuracy while optimizing for efficiency.","sidebar":"autogenerated_docs"},"guides/index":{"id":"guides/index","title":"Guides","description":"Access FAQs, a glossary of terms, and insightful research papers to deepen your knowledge of Neural Magic\'s technology.","sidebar":"autogenerated_docs"},"home":{"id":"home","title":"What is Neural Magic?","description":"Neural Magic empowers you to optimize and deploy deep learning models on CPUs with GPU-class performance. Unlock efficiency, accessibility, and cost savings with our software solutions.","sidebar":"autogenerated_docs"},"llms/guides/hf-llm-to-deepsparse":{"id":"llms/guides/hf-llm-to-deepsparse","title":"Convert LLMs From Hugging Face","description":"This guide is for people interested in exporting their Hugging Face-compatible LLMs to work in DeepSparse.","sidebar":"autogenerated_docs"},"llms/guides/index":{"id":"llms/guides/index","title":"Guides","description":"Overview","sidebar":"autogenerated_docs"},"llms/guides/llm-serving-on-windows":{"id":"llms/guides/llm-serving-on-windows","title":"LLM Serving on Windows","description":"Here is a guide for running a large language model (LLM) for text generation on Windows using Windows Subsystem for Linux (WSL) and DeepSparse Server","sidebar":"autogenerated_docs"},"llms/guides/one-shot-llms-with-sparseml":{"id":"llms/guides/one-shot-llms-with-sparseml","title":"Compress LLMs With SparseGPT","description":"This page describes how to perform one-shot quantization of large language models using SparseML. This workflow requires a GPU with at least 16GB VRAM and 64GB of system RAM.","sidebar":"autogenerated_docs"},"llms/guides/why-weight-sparsity":{"id":"llms/guides/why-weight-sparsity","title":"Why is Sparsity Important for LLMs?","description":"Large Language Models (LLMs) have a large size that often poses challenges in terms of computational efficiency and memory usage. Weight sparsity is a technique that can significantly alleviate these issues, enhancing the practicality and scalability of LLMs. Here we outline the key benefits of weight sparsity in LLMs, focusing on three main aspects:","sidebar":"autogenerated_docs"},"llms/index":{"id":"llms/index","title":"LLMs - Causal Language Modeling","description":"Harness the power of causal language models for creative text generation tasks, including creative writing, dialogue simulation, and code writing assistance.","sidebar":"autogenerated_docs"},"llms/models/huggingface-models":{"id":"llms/models/huggingface-models","title":"Hugging Face Hub Models","description":"Hugging Face Hub models are DeepSparse-ready models that haven\'t gone through rigorous testing to ensure they meet certain criteria such as the ones in the SparseZoo. The process enables us to produce models faster without having to wait for the entire quality-assurance process. However, you should always perform evaluation for ensure the model\'s results are not completely off.","sidebar":"autogenerated_docs"},"llms/models/index":{"id":"llms/models/index","title":"Models","description":"","sidebar":"autogenerated_docs"},"llms/models/sparsezoo-models":{"id":"llms/models/sparsezoo-models","title":"SparseZoo Models","description":"SparseZoo models are models that have gone a rigorous process to ensure that they recover most of the accuracy after pruning and quantization. These models are hosted on sparsezoo.com. The models are ready for use with DeepSparse, saving you the hassle of having to optimize common models.","sidebar":"autogenerated_docs"},"llms/serving-llms":{"id":"llms/serving-llms","title":"Serving LLMs","description":"DeepSparse is a CPU inference runtime that takes advantage of sparsity to accelerate neural network inference. Coupled with SparseML, our optimization library for pruning and quantizing your models, DeepSparse delivers exceptional inference performance on CPU hardware.","sidebar":"autogenerated_docs"},"llms/tutorials/index":{"id":"llms/tutorials/index","title":"Tutorials","description":"Overview","sidebar":"autogenerated_docs"},"nlp/index":{"id":"nlp/index","title":"Natural Language Processing","description":"Leverage the efficiency of Neural Magic for a range of NLP tasks, including token classification, text classification, and question-answering systems.","sidebar":"autogenerated_docs"},"nlp/question-answering/get-started/deploy":{"id":"nlp/question-answering/get-started/deploy","title":"Deployment","description":"","sidebar":"autogenerated_docs"},"nlp/question-answering/get-started/finetune":{"id":"nlp/question-answering/get-started/finetune","title":"Finetune","description":"","sidebar":"autogenerated_docs"},"nlp/question-answering/get-started/index":{"id":"nlp/question-answering/get-started/index","title":"Getting Started with Causal Language Modeling","description":"Content","sidebar":"autogenerated_docs"},"nlp/question-answering/get-started/sparsify":{"id":"nlp/question-answering/get-started/sparsify","title":"Sparsify","description":"","sidebar":"autogenerated_docs"},"nlp/question-answering/index":{"id":"nlp/question-answering/index","title":"Question Answering","description":"Check out the links on the left to get started!","sidebar":"autogenerated_docs"},"nlp/question-answering/models/index":{"id":"nlp/question-answering/models/index","title":"Models","description":"Overview","sidebar":"autogenerated_docs"},"nlp/question-answering/tutorials/index":{"id":"nlp/question-answering/tutorials/index","title":"Tutorials","description":"Overview","sidebar":"autogenerated_docs"},"nlp/text-classification/get-started/deploy":{"id":"nlp/text-classification/get-started/deploy","title":"Deployment","description":"","sidebar":"autogenerated_docs"},"nlp/text-classification/get-started/finetune":{"id":"nlp/text-classification/get-started/finetune","title":"Finetune","description":"","sidebar":"autogenerated_docs"},"nlp/text-classification/get-started/index":{"id":"nlp/text-classification/get-started/index","title":"Getting Started with Causal Language Modeling","description":"Content","sidebar":"autogenerated_docs"},"nlp/text-classification/get-started/sparsify":{"id":"nlp/text-classification/get-started/sparsify","title":"Sparsify","description":"","sidebar":"autogenerated_docs"},"nlp/text-classification/index":{"id":"nlp/text-classification/index","title":"Text Classification","description":"Check out the links on the left to get started!","sidebar":"autogenerated_docs"},"nlp/text-classification/models/index":{"id":"nlp/text-classification/models/index","title":"Models","description":"Overview","sidebar":"autogenerated_docs"},"nlp/text-classification/tutorials/index":{"id":"nlp/text-classification/tutorials/index","title":"Tutorials","description":"Overview","sidebar":"autogenerated_docs"},"nlp/token-classification/get-started/deploy":{"id":"nlp/token-classification/get-started/deploy","title":"Deployment","description":"","sidebar":"autogenerated_docs"},"nlp/token-classification/get-started/finetune":{"id":"nlp/token-classification/get-started/finetune","title":"Finetune","description":"","sidebar":"autogenerated_docs"},"nlp/token-classification/get-started/index":{"id":"nlp/token-classification/get-started/index","title":"Getting Started with Causal Language Modeling","description":"Content","sidebar":"autogenerated_docs"},"nlp/token-classification/get-started/sparsify":{"id":"nlp/token-classification/get-started/sparsify","title":"Sparsify","description":"","sidebar":"autogenerated_docs"},"nlp/token-classification/index":{"id":"nlp/token-classification/index","title":"Token Classification","description":"Check out the links on the left to get started!","sidebar":"autogenerated_docs"},"nlp/token-classification/models/index":{"id":"nlp/token-classification/models/index","title":"Models","description":"Overview","sidebar":"autogenerated_docs"},"nlp/token-classification/tutorials/index":{"id":"nlp/token-classification/tutorials/index","title":"Tutorials","description":"Overview","sidebar":"autogenerated_docs"},"products/deepsparse/index":{"id":"products/deepsparse/index","title":"DeepSparse","description":"","sidebar":"autogenerated_docs"},"products/deepsparse/releases":{"id":"products/deepsparse/releases","title":"DeepSparse Releases","description":"Versions","sidebar":"autogenerated_docs"},"products/index":{"id":"products/index","title":"Products","description":"Gain a comprehensive understanding of Neural Magic\'s core products (SparseML, DeepSparse, SparseZoo) and their key features.","sidebar":"autogenerated_docs"},"products/sparseml/index":{"id":"products/sparseml/index","title":"SparseML","description":"","sidebar":"autogenerated_docs"},"products/sparseml/releases":{"id":"products/sparseml/releases","title":"SparseML Releases","description":"Versions","sidebar":"autogenerated_docs"},"products/sparsezoo/index":{"id":"products/sparsezoo/index","title":"SparseZoo","description":"","sidebar":"autogenerated_docs"},"products/sparsezoo/releases":{"id":"products/sparsezoo/releases","title":"SparseZoo Releases","description":"Versions","sidebar":"autogenerated_docs"}}}')}}]);