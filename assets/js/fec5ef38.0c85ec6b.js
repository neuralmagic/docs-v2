"use strict";(self.webpackChunkdocs_neuralmagic_com=self.webpackChunkdocs_neuralmagic_com||[]).push([[8923],{5202:e=>{e.exports=JSON.parse('{"label":"sparsezoo","permalink":"/docs-v2/tags/sparsezoo","allTagsPath":"/docs-v2/tags","count":4,"items":[{"id":"get-started/deploy","title":"Deploying LLMs","description":"Deploy large language models (LLMs) for text generation using Neural Magic\'s DeepSparse. This doc includes code examples, performance benchmarking, and server setup.","permalink":"/docs-v2/get-started/deploy"},{"id":"get-started/install/sparsezoo","title":"Installing SparseZoo","description":"Install SparseZoo, Neural Magic\'s repository of pre-sparsified models, or learn how to access it through SparseML and DeepSparse.","permalink":"/docs-v2/get-started/install/sparsezoo"},{"id":"get-started/optimize","title":"Optimizing LLMs","description":"Optimize large language models (LLMs) for efficient inference using one-shot pruning and quantization. Learn how to improve model performance and reduce costs without sacrificing accuracy.","permalink":"/docs-v2/get-started/optimize"},{"id":"get-started/finetune","title":"Sparse Finetuning with LLMs","description":"Improve the performance of your large language models (LLMs) through finetuning with Neural Magic\'s SparseML. Optimize LLMs for specific tasks while maintaining accuracy.","permalink":"/docs-v2/get-started/finetune"}],"unlisted":false}')}}]);