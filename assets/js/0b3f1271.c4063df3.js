"use strict";(self.webpackChunkdocs_neuralmagic_com=self.webpackChunkdocs_neuralmagic_com||[]).push([[849],{3238:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>p,frontMatter:()=>s,metadata:()=>r,toc:()=>d});var a=t(5893),i=t(1151);const s={tags:["Neural Magic","DeepSparse","SparseZoo","SparseML","Model Finetuning","AI Training"],keywords:["Neural Network Finetuning","Sparse Training","Model Adaptation","AI Enhancement","Model Customization"],description:"A detailed guide on finetuning sparse models with Neural Magic\u2019s suite, focusing on techniques for both Generative AI and Object Detection models.",sidebar_label:"Finetune",sidebar_position:3},o="Sparse Finetuning",r={id:"get-started/finetune",title:"Sparse Finetuning",description:"A detailed guide on finetuning sparse models with Neural Magic\u2019s suite, focusing on techniques for both Generative AI and Object Detection models.",source:"@site/docs/get-started/finetune.mdx",sourceDirName:"get-started",slug:"/get-started/finetune",permalink:"/next/get-started/finetune",draft:!1,unlisted:!1,editUrl:"https://github.com/neuralmagic/docs/docs/get-started/finetune.mdx",tags:[{label:"Neural Magic",permalink:"/next/tags/neural-magic"},{label:"DeepSparse",permalink:"/next/tags/deep-sparse"},{label:"SparseZoo",permalink:"/next/tags/sparse-zoo"},{label:"SparseML",permalink:"/next/tags/sparse-ml"},{label:"Model Finetuning",permalink:"/next/tags/model-finetuning"},{label:"AI Training",permalink:"/next/tags/ai-training"}],version:"current",sidebarPosition:3,frontMatter:{tags:["Neural Magic","DeepSparse","SparseZoo","SparseML","Model Finetuning","AI Training"],keywords:["Neural Network Finetuning","Sparse Training","Model Adaptation","AI Enhancement","Model Customization"],description:"A detailed guide on finetuning sparse models with Neural Magic\u2019s suite, focusing on techniques for both Generative AI and Object Detection models.",sidebar_label:"Finetune",sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"Deploy",permalink:"/next/get-started/deploy"},next:{title:"sparsify",permalink:"/next/get-started/sparsify"}},l={},d=[{value:"Generative AI - LLMs",id:"generative-ai---llms",level:2},{value:"Hugging Face Datasets:",id:"hugging-face-datasets",level:4},{value:"CSV:",id:"csv",level:4},{value:"JSONL Example:",id:"jsonl-example",level:4},{value:"Training",id:"training",level:3},{value:"Evaluation",id:"evaluation",level:3},{value:"Inference",id:"inference",level:3},{value:"CV - Object Detection",id:"cv---object-detection",level:2},{value:"Training",id:"training-1",level:3},{value:"Evaluation",id:"evaluation-1",level:3},{value:"Exporting",id:"exporting",level:3},{value:"Deployment",id:"deployment",level:3}];function c(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.a)(),...e.components},{Details:t,TabItem:s,Tabs:o}=n;return t||u("Details",!0),s||u("TabItem",!0),o||u("Tabs",!0),(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.h1,{id:"sparse-finetuning",children:"Sparse Finetuning"}),"\n",(0,a.jsx)(n.p,{children:"This guide provides detailed instructions on finetuning sparse models using Neural Magic's suite, including DeepSparse, SparseZoo, and SparseML.\nYou'll learn about the benefits of sparse finetuning, which combines the efficiency of sparsity with the adaptability of finetuning, enhancing model performance on specific tasks or datasets."}),"\n",(0,a.jsx)(n.h2,{id:"generative-ai---llms",children:"Generative AI - LLMs"}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsxs)(n.p,{children:["Ensure you have the necessary packages installed for Generative AI as outlined in the ",(0,a.jsx)(n.a,{href:"./install#generative-ai",children:"Install Guide"}),"."]})}),"\n",(0,a.jsx)(n.p,{children:"In this section, we focus on finetuning large language models (LLMs) for specific tasks or datasets.\nThe example model used here is a pre-sparsified, 7b parameter version of Llama 2 that was sparsified on the Platypus instruction tuning dataset from the SparseZoo:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-text",children:"zoo:llama2-7b-open_platypus_orca_llama2_pretrain-pruned50\n"})}),"\n",(0,a.jsx)(n.p,{children:"After training, the model will additionally be quantized to 8-bit integer weights and activations, resulting in a model that is both sparse and quantized.\nA quantized version of the above model is used in the evaluation and inference sections below with the following stub.\nBe sure to replace the stub with the path to the model you trained:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-text",children:"zoo:llama2-7b-open_platypus_orca_llama2_pretrain-pruned50_quantized\n"})}),"\n",(0,a.jsxs)(n.p,{children:["For additional models, explore the ",(0,a.jsx)(n.a,{href:"https://sparsezoo.neuralmagic.com/?modelSet=generative_ai",children:"Generative AI models in the SparseZoo"}),"."]}),"\n",(0,a.jsx)(n.p,{children:"The example dataset used here is the Helpful Instructions dataset from the Hugging Face H4 team.\nBe sure to replace the dataset with your desired one in the training section below:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-text",children:"HuggingFaceH4/helpful_instructions\n"})}),"\n",(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Data Preparation"}),(0,a.jsx)(n.p,{children:"Preparing your dataset to work with the expected format is key to enabling the finetuning pipelines to work.\nExamples are provided below for the supported formats include Hugging Face datasets, CSV files, and JSONL files."}),(0,a.jsx)(n.h4,{id:"hugging-face-datasets",children:"Hugging Face Datasets:"}),(0,a.jsxs)(o,{children:[(0,a.jsx)(s,{value:"bash",label:"Bash",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'--data "HuggingFaceH4/helpful_instructions"\n'})})}),(0,a.jsx)(s,{value:"python",label:"Python",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from datasets import load_dataset\n\ndataset = load_dataset("HuggingFaceH4/helpful_instructions", name="all")\n'})})})]}),(0,a.jsx)(n.h4,{id:"csv",children:"CSV:"}),(0,a.jsxs)(n.p,{children:["To ensure the CSV file is formatted correctly, it should have two columns: ",(0,a.jsx)(n.code,{children:"prompt"})," and ",(0,a.jsx)(n.code,{children:"completion"}),".\nThe ",(0,a.jsx)(n.code,{children:"prompt"})," column should contain the prompt text, and the ",(0,a.jsx)(n.code,{children:"completion"})," column should contain the expected completion text.\nHere's an example of a CSV file for the helpful instructions dataset formatted correctly:"]}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-csv",children:'prompt,completion\n"""Make a list of 10 ways to help students improve their study skills.""","""1. Make a schedule for studying and stick to it. 2. Study in the same place every time. 3. Set goals for yourself. 4. Take breaks when you need them. 5. Don\'t cram before an exam. 6. Get enough sleep. 7. Eat healthy food. 8. Exercise regularly. 9. Find a study partner. 10. Reward yourself after completing a task."""\n"""Task: Find out what are the key topics in the document? output \\""topic 1\\"", \\""topic 2\\"", ... , \\""topic n\\"". The United States has withdrawn from the Paris Climate Agreement.""","""Topic 1"""\n"""Given a list of numbers, find out if they are prime or not. you can answer \\""prime\\"" or \\""not prime\\"". Input: List: 1, 4, 6, 8, 9""","""not prime"""\n"""Task: What are some of your favorite websites, and why do you visit them often?""","""- Stack Overflow - I like to learn new things, and this is a great place to find answers to questions."""\n"""Should i take this class or not? The professor of this class is not good at all. He doesn\'t teach well and he is always late for class.""","""No"""\n'})}),(0,a.jsx)(n.h4,{id:"jsonl-example",children:"JSONL Example:"}),(0,a.jsxs)(n.p,{children:["To ensure the JSONL file is formatted correctly, it should contain a JSON object on each line.\nEach JSON object should have a ",(0,a.jsx)(n.code,{children:"prompt"})," key and a ",(0,a.jsx)(n.code,{children:"completion"})," key.\nThe ",(0,a.jsx)(n.code,{children:"prompt"})," key should contain the prompt text, and the ",(0,a.jsx)(n.code,{children:"completion"})," key should contain the expected completion text.\nHere's an example of a JSONL file for the helpful instructions dataset formatted correctly:"]}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-json",children:'{"prompt": "\\"Make a list of 10 ways to help students improve their study skills.\\"", "completion": "\\"1. Make a schedule for studying and stick to it. 2. Study in the same place every time. 3. Set goals for yourself. 4. Take breaks when you need them. 5. Don\'t cram before an exam. 6. Get enough sleep. 7. Eat healthy food. 8. Exercise regularly. 9. Find a study partner. 10. Reward yourself after completing a task.\\""}\n{"prompt": "\\"Task: Find out what are the key topics in the document? output \\\\\\"topic 1\\\\\\", \\\\\\"topic 2\\\\\\", ... , \\\\\\"topic n\\\\\\". The United States has withdrawn from the Paris Climate Agreement.\\"", "completion": "\\"Topic 1\\""}\n{"prompt": "\\"Given a list of numbers, find out if they are prime or not. you can answer \\\\\\"prime\\\\\\" or \\\\\\"not prime\\\\\\". Input: List: 1, 4, 6, 8, 9\\"", "completion": "\\"not prime\\""}\n{"prompt": "\\"Task: What are some of your favorite websites, and why do you visit them often?\\"", "completion": "\\"- Stack Overflow - I like to learn new things, and this is a great place to find answers to questions.\\""}\n{"prompt": "\\"Should i take this class or not? The professor of this class is not good at all. He doesn\'t teach well and he is always late for class.\\"", "completion": "\\"No\\""}\n'})})]}),"\n",(0,a.jsx)(n.h3,{id:"training",children:"Training"}),"\n",(0,a.jsx)(n.p,{children:"Training the sparse model further on the targeted dataset utilizing SparseML and Recipes is simple and straightforward.\nIn doing this, the performant, sparse architecture is adapted to the specific task or dataset, enhancing its performance for the targeted use case.\nTo start the training process, utilize the following command:"}),"\n",(0,a.jsxs)(o,{children:[(0,a.jsx)(s,{value:"bash",label:"Bash",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'sparseml.transformers.text_generation.apply \\\n    --model "zoo:llama2-7b-open_platypus_orca_llama2_pretrain-pruned50" \\\n    --data "HuggingFaceH4/helpful_instructions" \\\n    --recipe "zoo:llama2-7b-open_platypus_orca_llama2_pretrain-pruned50?recipe_type=transfer_quantize" \\\n    --epochs 1\n\n# <output>\n# TODO: add output\n# </output>\n'})})}),(0,a.jsx)(s,{value:"python",label:"Python",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from sparseml.transformers.text_generation import apply\n\napply(\n    model="zoo:llama2-7b-open_platypus_orca_llama2_pretrain-pruned50",\n    data="HuggingFaceH4/helpful_instructions",\n    recipe="zoo:llama2-7b-open_platypus_orca_llama2_pretrain-pruned50?recipe_type=transfer_quantize",\n    epochs=1,\n)\n\n# <output>\n# TODO: add output\n# </output>\n'})})})]}),"\n",(0,a.jsxs)(n.p,{children:["Once the training process is complete, the model will be saved to the ",(0,a.jsx)(n.code,{children:"./output"})," directory by default."]}),"\n",(0,a.jsx)(n.h3,{id:"evaluation",children:"Evaluation"}),"\n",(0,a.jsxs)(n.p,{children:["Once the model has been fine-tuned, evaulating its performance on the targeted dataset is simple and straightforward.\nSparseML is integrated with numerous evaluation libraries, including LM Eval Harness, Alpaca Eval Harness, BigCode, and more.\nFor the instruction tuned model created above, we'll use the LM Eval Harness to evaluate its performance across a variety of metrics.\nTo start the evaluation process, utilize the following command and replace the sample model with the ",(0,a.jsx)(n.code,{children:"./output"})," directory from the training process:"]}),"\n",(0,a.jsxs)(o,{children:[(0,a.jsx)(s,{value:"bash",label:"Bash",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'sparseml.evaluate \\\n    "zoo:llama2-7b-open_platypus_orca_llama2_pretrain-pruned50_quantized" \\\n    --integration "lm-eval-harness"\n\n# <output>\n# TODO: add output\n# </output>\n'})})}),(0,a.jsx)(s,{value:"python",label:"Python",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from sparseml import evaluate\n\nevaluate(\n    "zoo:llama2-7b-open_platypus_orca_llama2_pretrain-pruned50_quantized",\n    integration="lm-eval-harness"\n)\n\n# <output>\n# TODO: add output\n# </output>\n'})})})]}),"\n",(0,a.jsx)(n.h3,{id:"inference",children:"Inference"}),"\n",(0,a.jsx)(n.p,{children:"After finetuning and evaluation, the model is ready for inference.\nYou can load and utilize this model in PyTorch utilizing the following code:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from sparseml.transformers import SparseAutoModelForCausalLM, SparseAutoTokenizer\n\nmodel = SparseAutoModelForCausalLM.from_pretrained(\n    "zoo:llama2-7b-open_platypus_orca_llama2_pretrain-pruned50_quantized"\n)\ntokenizer = SparseAutoTokenizer.from_pretrained(\n    "zoo:llama2-7b-open_platypus_orca_llama2_pretrain-pruned50_quantized"\n)\ninputs = tokenizer(["PRMOPT"], return_tensors="pt")\ngenerated_ids = model.generate(**inputs)\noutputs = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\nprint(outputs)\n\n# <output>\n# TODO: add output\n# </output>\n'})}),"\n",(0,a.jsx)(n.p,{children:"However, the above code will not utilize the sparsity of the model.\nTo do this, you'll export the model to an ONNX format which DeepSparse can utilize.\nThe following code will export to the proper format in addition to injecting KV Cache for improved performance:"}),"\n",(0,a.jsxs)(o,{children:[(0,a.jsx)(s,{value:"bash",label:"Bash",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'sparseml.export \\\n    "zoo:llama2-7b-open_platypus_orca_llama2_pretrain-pruned50_quantized" \\\n    --task "text-generation" \\\n    --sequence_length 1024 \\\n    --output_path "./exported"\n\n# <output>\n# TODO: add output\n# </output>\n'})})}),(0,a.jsx)(s,{value:"python",label:"Python",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from sparseml import export\n\nexport(\n    "zoo:llama2-7b-open_platypus_orca_llama2_pretrain-pruned50_quantized",\n    task="text-generation",\n    sequence_length=1024,\n    output_path="./exported"\n)\n\n# <output>\n# TODO: add output\n# </output>\n'})})})]}),"\n",(0,a.jsxs)(n.p,{children:["Once the model has been exported, you can utilize the same commands as outlined in the ",(0,a.jsx)(n.a,{href:"./deploy",children:"Getting Started - Deploy Guide"})," to run performance inference on the exported sparse-quantized model."]}),"\n",(0,a.jsx)(n.h2,{id:"cv---object-detection",children:"CV - Object Detection"}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsxs)(n.p,{children:["Ensure you've installed the necessary packages for Object Detection as outlined in the ",(0,a.jsx)(n.a,{href:"./install#object-detection",children:"Install Guide"}),"."]})}),"\n",(0,a.jsx)(n.p,{children:"In this section, we cover finetuning object detection models. We use a pre-sparsified YOLOv5 model as an example:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-text",children:"zoo:yolov5-s-coco-pruned80_quantized\n"})}),"\n",(0,a.jsxs)(n.p,{children:["Discover more models at the ",(0,a.jsx)(n.a,{href:"https://sparsezoo.neuralmagic.com/?tasks=detection&modelSet=computer_vision",children:"SparseZoo's Object Detection section"}),"."]}),"\n",(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Data Preparation"}),(0,a.jsx)(n.p,{children:"Preparing your dataset effectively is key to successful finetuning. Supported formats include Hugging Face dataset aliases, CSV, and JSONL. Here are examples for each format:"}),(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Hugging Face Dataset Alias"}),":"]}),"\n"]}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from datasets import load_dataset\ndataset = load_dataset('coco', '202\n\n1')\n"})}),(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"CSV Format"}),":"]}),"\n"]}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import pandas as pd\ndataset = pd.read_csv('your_dataset.csv')\n"})}),(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"JSONL Format"}),":"]}),"\n"]}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import json\nwith open('your_dataset.jsonl', 'r') as file:\ndataset = [json.loads(line) for line in file]\n"})})]}),"\n",(0,a.jsx)(n.h3,{id:"training-1",children:"Training"}),"\n",(0,a.jsx)(n.p,{children:"Training your model on specific datasets for object detection tasks can greatly improve its accuracy and efficiency:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"CLI"}),":"]}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'sparseml.finetune --model "zoo:yolov5-s-coco-pruned80_quantized" --data "path/to/dataset"\n'})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Python API"}),":"]}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from sparseml import finetune\nfinetune("zoo:yolov5-s-coco-pruned80_quantized", data_path="path/to/dataset")\n'})}),"\n",(0,a.jsx)(n.h3,{id:"evaluation-1",children:"Evaluation"}),"\n",(0,a.jsx)(n.p,{children:"Evaluating your finetuned model is crucial for assessing its performance:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"CLI"}),":"]}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'sparseml.evaluate --model "zoo:yolov5-s-coco-pruned80_quantized" --data "path/to/validation_data"\n'})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Python API"}),":"]}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from sparseml import evaluate\nevaluate("zoo:yolov5-s-coco-pruned80_quantized", data_path="path/to/validation_data")\n'})}),"\n",(0,a.jsx)(n.h3,{id:"exporting",children:"Exporting"}),"\n",(0,a.jsx)(n.p,{children:"Export your finetuned model for deployment:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"CLI"}),":"]}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'sparseml.export --model "zoo:yolov5-s-coco-pruned80_quantized" --output_path "path/to/exported_model"\n'})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Python API"}),":"]}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from sparseml import export\nexport("zoo:yolov5-s-coco-pruned80_quantized", output_path="path/to/exported_model")\n'})}),"\n",(0,a.jsx)(n.h3,{id:"deployment",children:"Deployment"}),"\n",(0,a.jsxs)(n.p,{children:["For instructions on deploying your finetuned model, see our ",(0,a.jsx)(n.a,{href:"./deploy",children:"Deployment Guide"}),"."]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.p,{children:"For more information on the example tasks in this guide, other supported tasks, and custom integrations, explore the following resources:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"../generative-ai",children:"Generative AI"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"../computer-vision",children:"Computer Vision"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"../nlp",children:"Natural Language Processing"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"../custom-integrations",children:"Custom Integrations"})}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,i.a)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}function u(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}},1151:(e,n,t)=>{t.d(n,{Z:()=>r,a:()=>o});var a=t(7294);const i={},s=a.createContext(i);function o(e){const n=a.useContext(s);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),a.createElement(s.Provider,{value:n},e.children)}}}]);