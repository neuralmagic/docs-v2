---
tags:
- deepsparse
- installation
- setup
- inference engine
keywords:
- DeepSparse installation
- CPU inference
- ONNX
description: Install DeepSparse, Neural Magic's high-performance inference engine, for optimized deep learning model deployment on CPUs.
sidebar_label: DeepSparse
sidebar_position: 1
---

# Installing DeepSparse

DeepSparse is Neural Magic's inference engine, empowering you to run deep learning models on CPUs with exceptional performance and efficiency.
This guide covers various installation methods, including PyPI, Docker, and installation from the GitHub source code for advanced use cases.

## Prerequisites

### Hardware Requirements

- <b>CPU</b>: x86 with AVX2 instructions (Intel Haswell or newer, AMD Zen 2 or newer) or ARM v8.2 or newer.
- <b>RAM</b>: Minimum 1GB (model and configuration dependent)

### Software Requirements

- <b>OS:</b> Linux (Ubuntu, CentOS, RedHat, etc.). MacOS (beta).
- <b>Python:</b> 3.8 - 3.11
- <b>ONNX:</b> Version 1.5.0 - 1.15.0 (opset 11 or higher)

## Community Installation

### PyPI

For the most common use case, install the current release version of DeepSparse using PyPI:

<VersionInjector targetProduct="deepsparse" targetVersion="==VERSION" prepend="==">
    ```bash
    pip install deepsparse==VERSION
    ```
</VersionInjector>

### Docker

Deploy DeepSparse in a containerized environment using our Docker image:

<VersionInjector targetProduct="deepsparse" prepend="v" currentTag="latest">
    ```bash
    docker pull ghcr.io/neuralmagic/deepsparse:VERSION
    docker run -it ghcr.io/neuralmagic/deepsparse:VERSION
    ```
</VersionInjector>

### GitHub (Advanced)

For development purposes or advanced use cases, install directly from the GitHub repository:

<VersionInjector targetProduct="deepsparse" prepend="v" currentTag="main" ignoreNightly={true}>
    ```bash
    pip install git+https://github.com/neuralmagic/deepsparse.git@VERSION[dev]
    ```
</VersionInjector>

Or from a locally cloned repository:

<VersionInjector targetProduct="deepsparse" prepend="tags/v" currentTag="main" ignoreNightly={true}>
    ```bash
    git clone https://github.com/neuralmagic/deepsparse.git
    cd deepsparse
    git checkout VERSION
    pip install -e .[dev]
    ```
</VersionInjector>

## Enterprise Installation

### PyPI

DeepSparse Enterprise provides enhanced features and production-grade support.
See our [Enterprise Guide](/guides/enterprise) for obtaining a license key and more information.

<VersionInjector targetProduct="deepsparse-ent" ignoreNightly={true} targetVersion="==VERSION" prepend="==">
    ```bash
    pip install deepsparse-ent==VERSION
    ```
</VersionInjector>

## Specialized Installations

Install DeepSparse with tailored support with the following extras for domain-specific use cases and tasks.

### Generative AI: HuggingFace

For generative AI, particularly transformer architectures, this extra supports models like Llama, Mistral, MPT, GPT, and others.
It enables compatibility of HuggingFace's transformers pipelines and models to DeepSparse allowing performant and memory-efficient inference.

<VersionInjector targetProduct="deepsparse[llm]" targetVersion="==VERSION" prepend="==">
    ```bash
    pip install deepsparse[llm]==VERSION
    ```
</VersionInjector>

### Object Detection: YOLOv8

For object detection, this extra provides built-in support for YOLOv8 models.
It enables compatibility of YOLOv8 models and pipelines to DeepSparse, allowing performant and memory-efficient inference.

<VersionInjector targetProduct="deepsparse[yolov8]" targetVersion="==VERSION" prepend="==">
    ```bash
    pip install deepsparse[yolov8]==VERSION
    ```
</VersionInjector>

### Image Classification: TorchVision

For image classification, this extra provides built-in support for TorchVision models.
It enables compatibility of TorchVision models and pipelines to DeepSparse, allowing performant and memory-efficient inference.

<VersionInjector targetProduct="deepsparse[image_classification]" targetVersion="==VERSION" prepend="==">
    ```bash
    pip install deepsparse[image_classification]==VERSION
    ```
</VersionInjector>

### Natural Language Processing: HuggingFace

This extra provides built-in support for HuggingFace's transformers models for natural language processing.
It enables compatibility of HuggingFace's transformers pipelines and models to DeepSparse allowing performant and memory-efficient inference.

<VersionInjector targetProduct="deepsparse[transformers]" targetVersion="==VERSION" prepend="==">
    ```bash
    pip install deepsparse[transformers]==VERSION
    ```
</VersionInjector>

### DeepSparse Server

For HTTP serving of deep learning models, this extra provides built-in support for DeepSparse Server.
It enables serving any DeepSparse pipelines via HTTP and can be combined with other extras for additional model support.

<VersionInjector targetProduct="deepsparse[server]" targetVersion="==VERSION" prepend="==">
    ```bash
    pip install deepsparse[server]==VERSION
    ```
</VersionInjector>

### ONNX Runtime

This extra provides built-in support for ONNX Runtime for benchmarking and comparison purposes.
It enables running any DeepSparse pipelines via ONNX Runtime and can be combined with other extras for additional model support.

<VersionInjector targetProduct="deepsparse[onnxruntime]" targetVersion="==VERSION" prepend="==">
    ```bash
    pip install deepsparse[onnxruntime]==VERSION
    ```
</VersionInjector>

### Development

For development purposes, this extra provides built-in support for development tools.

<VersionInjector targetProduct="deepsparse[dev]" targetVersion="==VERSION" prepend="==">
    ```bash
    pip install deepsparse[dev]==VERSION
    ```
</VersionInjector>
