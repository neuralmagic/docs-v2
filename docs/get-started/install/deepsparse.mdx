---
tags:
- DeepSparse
- NeuralMagic
- Model Optimization
- Deep Learning
keywords:
- DeepSparse
- NeuralMagic
- Model Optimization
- Sparsity
description: Step-by-step guide for installing NeuralMagic's DeepSparse.
sidebar_label: DeepSparse
sidebar_position: 1
---

# Installing DeepSparse

Welcome to the DeepSparse installation guide.
Here, you'll find instructions for various installation methods including PyPI, Docker, and advanced options via GitHub.

:::note
The installation commands correspond to the version of DeepSparse you're viewing in the documentation.
:::

## Prerequisites

### Hardware Requirements

- CPU
    - x86 CPUs with a minimum of <Tooltip>AVX2</Tooltip> SIMD instructions such as Intel Haswell generation and later or AMD Zen 2 generation and later.
    - ARM CPUs with a minimum of v8.2.
- RAM
    - 1 GB minimum; however the minimum memory needed will depend on the configuration and model being run.

### Software Requirements

- OS
    - Linux is supported and is tested across Ubuntu, CentOS, and RedHat distributions.
    - MacOS is currently in beta.
    - Windows is not supported at this time. However, Windows users can install DeepSparse via Docker or a virtual machine.
- Python 3.8-3.11
- ONNX versions 1.5.0-1.15.0, ONNX opset version 11 or higher.

## Community Installation

### PyPI

To install the current version of DeepSparse via PyPI, utilize the following command:

<VersionInjector targetProduct="deepsparse" targetVersion="==VERSION" prepend="==">
    ```bash
    pip install deepsparse==VERSION
    ```
</VersionInjector>


To install the current version of DeepSparse via Docker, utilize the following commands:

<VersionInjector targetProduct="deepsparse" prepend="v" currentTag="latest">
    ```bash
    docker pull ghcr.io/neuralmagic/deepsparse:VERSION
    docker run -it ghcr.io/neuralmagic/deepsparse:VERSION
    ```
</VersionInjector>

### GitHub

Advanced users can install from source code by utilizing the following command::

<VersionInjector targetProduct="deepsparse" prepend="v" currentTag="main" ignoreNightly={true}>
    ```bash
    pip install git+https://github.com/neuralmagic/deepsparse.git@VERSION
    ```
</VersionInjector>

Additionally, the following commands install via GitHub, but from a locally cloned repository:

<VersionInjector targetProduct="deepsparse" prepend="tags/v" currentTag="main" ignoreNightly={true}>
    ```bash
    git clone https://github.com/neuralmagic/deepsparse.git
    cd deepsparse
    git checkout VERSION
    pip install -e .
    ```
</VersionInjector>

## Enterprise Installation

### PyPI

DeepSparse Enterprise is available for companies to utilize in production environments and requires a license key to be installed alongside the package.

To install the current version of DeepSparse Enterprise via PyPI, utilize the following command:

<VersionInjector targetProduct="deepsparse-enterprise" ignoreNightly={true} targetVersion="==VERSION" prepend="==">
    ```bash
    pip install deepsparse-enterprise==VERSION
    ```
</VersionInjector>

To obtain a license key or for more information on how to install a license key, see the [Enterprise Guide](/guides/enterprise).

## Specialized Installations

### Generative AI: HuggingFace

For generative AI, particularly transformer architectures, this extra provides built in support for models like Llama, Mistral, MPT, GPT, and others.
It enables compatibility of HuggingFace's transformers pipelines and models to DeepSparse allowing performant and memory-efficient inference.

<VersionInjector targetProduct="deepsparse[llm]" targetVersion="==VERSION" prepend="==">
```bash
pip install deepsparse[llm]==VERSION
```
</VersionInjector>

### Object Detection: YOLOv8

For object detection, this extra provides built in support for YOLOv8 models.
It enables compatibility of YOLOv8 models and pipelines to DeepSparse allowing performant and memory-efficient inference.

<VersionInjector targetProduct="deepsparse[yolov8]" targetVersion="==VERSION" prepend="==">
    ```bash
    pip install deepsparse[yolov8]==VERSION
    ```
</VersionInjector>

### Image Classification: TorchVision

For image classification, this extra provides built in support for TorchVision models.
It enables compatibility of TorchVision models and pipelines to DeepSparse allowing performant and memory-efficient inference.

<VersionInjector targetProduct="deepsparse[image_classification]" targetVersion="==VERSION" prepend="==">
    ```bash
    pip install deepsparse[image_classification]==VERSION
    ```
</VersionInjector>

### Natural Language Processing: HuggingFace

For natural language processing, this extra provides built in support for HuggingFace's transformers models.
It enables compatibility of HuggingFace's transformers pipelines and models to DeepSparse allowing performant and memory-efficient inference.

<VersionInjector targetProduct="deepsparse[transformers]" targetVersion="==VERSION" prepend="==">
```bash
pip install deepsparse[transformers]==VERSION
```
</VersionInjector>

### DeepSparse Server

For HTTP serving of DeepLearning models, this extra provides built in support for DeepSparse Server.
It enables any DeepSparse pipelines to be served via HTTP and can be combined with other extras for additional model support.

<VersionInjector targetProduct="deepsparse[server]" targetVersion="==VERSION" prepend="==">
```bash
pip install deepsparse[server]==VERSION
```
</VersionInjector>

### ONNX Runtime

For benchmarking and comparison purposes, this extra provides built in support for ONNX Runtime.
It enables any DeepSparse pipelines to be run via ONNX Runtime and can be combined with other extras for additional model support.

<VersionInjector targetProduct="deepsparse[onnxruntime]" targetVersion="==VERSION" prepend="==">
```bash
pip install deepsparse[onnxruntime]==VERSION
```
</VersionInjector>

### Development

For development purposes, this extra provides built in support for development tools.

<VersionInjector targetProduct="deepsparse[dev]" targetVersion="==VERSION" prepend="==">
```bash
pip install deepsparse[dev]==VERSION
```
</VersionInjector>
