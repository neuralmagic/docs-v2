---
slug: /
tags:
- neural-magic
- deep-learning
- model-optimization
- sparsification
- cpu-deployment
keywords:
- Neural Magic
- deep learning optimization
- CPU inference
- sparse models
- SparseML
- DeepSparse
sidebar_label: Home
description: Neural Magic empowers you to optimize and deploy deep learning models on CPUs with GPU-class performance. Unlock efficiency, accessibility, and cost savings with our software solutions.
sidebar_position: 0
---

# Neural Magic Documentation

Welcome to software-delivered AI... Welcome to Neural Magic!
Neural Magic empowers you to deploy deep learning models on standard CPUs, delivering GPU-class performance without the specialized hardware costs.
Our software solutions make AI accessible, efficient, and sustainable.

:::tip[HIGHLIGHTS]
- [view](https://neuralmagic.com/blog/bringing-the-neural-magic-to-gpus/) Blog: Neural Magic Leaps Into GPU Acceleration

- [view](https://github.com/neuralmagic/nm-vllm) New Repo: nm-vllm

:::

![Neural Magic Flows](/img/nm-flows.png)

## Selecting a Model

Start by choosing the ideal model for your project:

- <b>Neural Magic's Model Repositories:</b> Discover a vast selection of pre-sparsified models across popular use cases in our [SparseZoo](https://sparsezoo.neuralmagic.com/) and [Hugging Face](https://huggingface.co/neuralmagic) repositories. These models are ready for immediate, high-performance deployment.
- <b>Custom Models:</b> Easily integrate your PyTorch or ONNX models into Neural Magic's workflow, applying cutting-edge optimization and deployment techniques tailored to your specific needs.

## Optimizing a Model

Achieve unmatched model efficiency with Neural Magic's SparseML. This powerful toolkit leverages state-of-the-art research to streamline your optimization process:

- <b>Advanced Sparsification:</b> Employ sophisticated pruning and quantization strategies to shrink model size and boost inference speed.
- <b>User-Friendly Approach:</b>  SparseML is intuitive and accessible, empowering users at all levels to apply advanced optimization techniques effortlessly.


## Deploying a Model

Deploy your optimized model with exceptional performance on CPUs using Neural Magic's DeepSparse:

- <b>CPU-Optimized Performance:</b> DeepSparse harnesses the potential of sparsity to deliver GPU-level performance on commodity CPUs, maximizing hardware utilization.
- <b>Seamless Integration:</b> Deploy easily, as DeepSparse smoothly integrates into your existing applications, minimizing development overhead.

## Next Steps

Ready to revolutionize your deep learning workflow? Dive into our detailed guides and documentation:

### Sections

<DocCardList items={['get-started/index', 'guides/index', 'products/index', 'details/index']} />

### Tasks

<DocCardList items={['llms/index', 'computer-vision/index', 'nlp/index']} />

<br></br>

---

✅ <b>Connect:</b> Join our [Slack community](https://join.slack.com/t/discuss-neuralmagic/shared_invite/zt-q1a1cnvo-YBoICSIw3L1dmQpjBeDurQ) for support.

✅ <b>Subscribe</b> Stay informed with our regular [email updates](https://neuralmagic.com/deep-sparse-community/#subscribe).

✅ <b>Contribute:</b> Shape the future of Neural Magic on [GitHub](https://github.com/neuralmagic) (⭐s appreciated!).

✅ <b>Feedback:</b> Help us refine our [documentation](https://github.com/neuralmagic/docs).
