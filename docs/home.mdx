---
slug: /
title: Home
sidebar_position: 0
---

# Neural Magic Docs

Welcome to software-delivered AI... Welcome to Neural Magic!
We enable you to deploy deep learning models on commodity CPUs with GPU-class performance.

Neural Magic's guided experiences and documentation will show you how to integrate performant and optimized deep learning into your application.
Our guided experiences and documentation enable you to discover how to unlock the full potential of your ML environments through increased performance, decreased costs, and decreased energy usage.

![Neural Magic Flows](/img/nm-flows.png)

## Selecting a Model

Begin your journey with Neural Magic by selecting the right model for your application. You have two primary options:

1. Neural Magic's Pre-Sparsified Models: Neural Magic's research teams publish pre-sparsified versions of popular models and use cases that you can immediately utilize for performant deployments with little knowledge or effort towards sparsification techniques. These models are avaialble on [Neural Magic's SparseZoo](https://sparsezoo.neuralmagic.com/) and [Neural Magic's Hugging Face Organization](https://huggingface.co/neuralmagic).
2. Your Own Models: If you have a custom model developed in PyTorch or ONNX format, you can directly integrate it with Neural Magic’s tools. This flexibility allows you to apply Neural Magic’s optimization and deployment technologies to models specifically tailored to your unique use cases.

## Optimizing a Model

Optimizing your models for better performance and efficiency is crucial. With Neural Magic’s SparseML, this process is streamlined using state-of-the-art (SOTA) research techniques. SparseML provides:

- Advanced Sparsification Techniques: Utilize cutting-edge research in sparsity to optimize your models. This includes techniques like pruning and quantization, which help in reducing model size and improving inference speed.
- Accessible Optimization: SparseML is designed to be user-friendly, enabling anyone to apply these optimization techniques to their models. Whether you are a seasoned ML practitioner or new to the field, SparseML guides you through the process of optimizing your models for better performance.


## Deploying a Model

With Neural Magic’s DeepSparse, you can deploy your selected model with exceptional performance on CPUs. DeepSparse is designed to provide GPU-class performance, solely utilizing CPU resources. This approach brings a significant advantage in terms of accessibility and cost-effectiveness for deploying deep learning models. Here’s what DeepSparse offers:

- Efficient CPU Deployments: Leveraging the power of sparsity, DeepSparse allows you to deploy models on CPUs without compromising on performance, making the most of the available hardware.
- Seamless Integration: DeepSparse is built to be easily integrated into your existing applications, reducing the need for extensive code rewriting and accelerating the deployment process.

## Next Steps

This was a quick look at Neural Magic’s suite of products.
Now, we invite you to explore our products through guided experiences and documentation.

### Sections

The following sections will help you get started with Neural Magic's products:

<DocCardList items={['get-started/index', 'guides/index', 'products/index', 'details/index']} />

### Tasks

If you have a specific domain or task in mind, dive into the following sections:

<DocCardList items={['generative-ai/index', 'computer-vision/index', 'nlp/index']} />

<br></br>

---

✅ Join our [community](https://join.slack.com/t/discuss-neuralmagic/shared_invite/zt-q1a1cnvo-YBoICSIw3L1dmQpjBeDurQ) if you need any help or [subscribe](https://neuralmagic.com/deep-sparse-community/#subscribe) for regular email updates.

✅ Check out our [GitHub repositories](https://github.com/neuralmagic) and give us a ⭐.

✅ Help us improve this [documentation](https://github.com/neuralmagic/docs).
